{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"What is Recce (Data Review Agent)","text":""},{"location":"#what-is-recce-data-review-agent","title":"What is Recce (Data Review Agent)","text":"<p>Know exactly how code changes impact your data.</p> <p>Recce is a Data Review Agent that automates data validation for pull requests. When you open a PR, it compares your dev environment against production and surfaces schema changes, data diffs, row counts, and downstream impacts. You see what changed, what it affects, and what passed, all before you merge.</p> <p>No more merging PRs where the pipeline succeeded but the data is quietly wrong.</p>"},{"location":"#how-recce-works","title":"How Recce Works","text":"<p>When you open a PR with data changes, Recce automatically:</p> <ol> <li>Runs data diffing: The best practice to validate data changes</li> <li>Analyzes impact: Identifies what changed down to the column level using Column-Level Lineage (CLL)</li> <li>Reviews first: The agent provides a data review summary explaining the change and its impact</li> <li>Surfaces what matters: Shows only impacted items, not every downstream table</li> <li>Opens exploration: Spins up a Recce instance where you can run additional diffs, explore lineage, and investigate deeper</li> </ol> <p>You review the agent's findings, add notes, and approve with confidence, not blind trust.</p> <p></p> <ol> <li>PR Created</li> <li>Recce Triggered</li> <li>Agent Analyzes Production vs. Development Data </li> <li>Agent Generates Review Summary</li> <li>Human Explore in Recce Instance</li> <li>Human Reviews Approves</li> <li>PR Merges</li> </ol> <p>Example of Recce agent summary in a GitHub PR comment:  </p>"},{"location":"#automate-agent-data-review-with-cicd","title":"Automate Agent Data Review with CI/CD","text":"<p>Recce delivers value through CI/CD integration. Without it, you waste time triaging false alerts from source data updates and manually comparing environments hoping you caught everything.</p> <p>With CI/CD:</p> <ul> <li>Every PR gets automatic validation</li> <li>Base and current environments are set up automatically</li> <li>Agent reviews before you do</li> <li>Checks accumulate as organizational knowledge (preset checks)</li> </ul>"},{"location":"#when-to-use-recce","title":"When to Use Recce","text":"<ul> <li>Business-critical data: Data that's customer-facing or revenue-impacting</li> <li>Team collaboration: When reviewers need to understand impact, not just see code changes</li> <li>Standardized validation: When you need consistent review across senior and junior team members</li> <li>Unknown unknowns: When you can't predict what might break from a change</li> </ul>"},{"location":"#when-not-to-use","title":"When Not to Use","text":"<ul> <li>Teams that accept errors on production and fix later</li> <li>Exploratory analysis that won't go to production</li> </ul>"},{"location":"#faq","title":"FAQ","text":"<p>Does Recce work without CI/CD? Yes, you can run Recce locally for dev sessions. But CI/CD unlocks the full value: automatic validation on every PR without manual setup.</p> <p>What data platforms does Recce support? Recce works with data warehouses like Snowflake, BigQuery, Redshift, and Databricks. See Connect to Warehouse for setup.</p>"},{"location":"#related","title":"Related","text":"<ul> <li>Interactive Demo: Try the Data Review Agent</li> <li>Tutorial: Get Started with Recce Cloud</li> <li>Blog: The Problem with Data PR Reviews: Where Do You Even Start?</li> </ul>"},{"location":"1-whats-recce/community-support/","title":"Community & Support","text":""},{"location":"1-whats-recce/community-support/#community-support","title":"Community &amp; Support","text":"<p>Here's where you can get in touch with the Recce team and find support:</p> <ul> <li>Our discord</li> <li>dbt Slack in the #tools-recce channel</li> <li>Email us help@reccehq.com</li> </ul> <p>If you believe you have found a bug on our open source, or there is some missing functionality in Recce, please open a GitHub Issue.</p>"},{"location":"1-whats-recce/community-support/#recce-on-the-web","title":"Recce on the web","text":"<p>You can follow along with news about Recce and blogs from our team in the following places:</p> <ul> <li>LinkedIn</li> <li>Recce Blog</li> <li>@datarecce on Twitter/X</li> <li>@DataRecce@mastodon.social on Mastodon</li> <li>@datarecce.bsky.social on BlueSky</li> </ul>"},{"location":"1-whats-recce/community-support/#subscribe-to-our-newsletter","title":"Subscribe to our newsletter","text":"<p>Stay updated with Recce news, data engineering insights, and product updates.</p> Sign up for Recce Updates"},{"location":"2-getting-started/get-started-jaffle-shop/","title":"Open Source Tutorial","text":"<p>Jaffle Shop is an example project officially provided by dbt Labs. This document uses jaffle_shop_duckdb to enable you to start using Recce locally from scratch within five minutes.</p> <p>Tip</p> <p>DuckDB projects like jaffle_shop_duckdb don\u2019t use a server-based connection or cloud warehouse credentials. Be aware that a few setup steps differ from those for cloud-based warehouses.</p>"},{"location":"2-getting-started/get-started-jaffle-shop/#step-by-step","title":"Step by Step","text":"<ol> <li>Clone the \u201cJaffle Shop\u201d dbt data project    <pre><code>git clone git@github.com:dbt-labs/jaffle_shop_duckdb.git\ncd jaffle_shop_duckdb\n</code></pre></li> <li>Prepare virtual env    <pre><code>python -m venv venv\nsource venv/bin/activate\n</code></pre></li> <li>Installation    <pre><code>pip install -r requirements.txt\npip install recce\n</code></pre></li> <li>Provide additional environment to compare    Edit <code>./profiles.yml</code> to add one more target to serve as the base environment for comparison.    Note: This step is only necessary for file-based engines like DuckDB. For cloud warehouses (e.g., Snowflake, BigQuery), Recce auto-detects your active dbt profile and schema, so no changes required.    <pre><code>jaffle_shop:\n  target: dev\n  outputs:\n  dev:\n    type: duckdb\n    path: 'jaffle_shop.duckdb'\n    threads: 24\n+ prod:\n+   type: duckdb\n+   path: 'jaffle_shop.duckdb'\n+   schema: prod\n+   threads: 24\n</code></pre></li> <li>Prepare production environment    Using DuckDB, you need to generate the artifacts for the base environment. Checkout the\u00a0<code>main</code>\u00a0branch of your project and generate the required artifacts into\u00a0<code>target-base</code>. You can skip\u00a0<code>dbt build</code>\u00a0if this environment already exists.    Note: This step is only necessary for file-based engines like DuckDB. For most data warehouses, you don\u2019t need to re-run production locally. You can download the dbt artifacts generated from the main branch, and save them to a <code>target-base/</code> folder.    <pre><code>dbt seed --target prod\ndbt run --target prod\ndbt docs generate --target prod --target-path ./target-base\n</code></pre></li> <li>Prepare development environment. First, edit an existing model <code>./models/staging/stg_payments.sql</code>.    <pre><code>...\n\nrenamed as (\n         payment_method,\n\n-        -- `amount` is currently stored in cents, so we convert it to dollars\n-        amount / 100 as amount\n+        amount\n\n         from source\n)\n</code></pre>    run on development environment.    <pre><code>dbt seed\ndbt run\ndbt docs generate\n</code></pre></li> <li>Run the recce server    <pre><code>recce server\n</code></pre>    Open the link http://0.0.0.0:8000, you can see the lineage diff    </li> <li>Switch to the Query tab, run this query    <pre><code>select * from {{ ref(\"orders\") }} order by 1\n</code></pre>    Click the <code>Run Diff</code> or press <code>Cmd + Shift + Enter</code>    Click on the \ud83d\udd11 icon next to the <code>order_id</code> column to compare records that are uniquely identified by their <code>order_id</code>.    </li> <li>Click the blue <code>Add to Checklist</code> button on the right bottom corner to add the query result to checklist    </li> </ol>"},{"location":"2-getting-started/get-started-jaffle-shop/#whats-next","title":"What\u2019s Next","text":"<p>By following this DuckDB tutorial, you\u2019ve seen how Recce works locally. You can now return to the Open Source Setup to set up Recce with your cloud data warehouse.</p> <p>Got questions? Let us know. We're happy to help!</p>"},{"location":"2-getting-started/gitlab-pat-guide/","title":"GitLab Personal Access Token","text":""},{"location":"2-getting-started/gitlab-pat-guide/#gitlab-personal-access-token-setup","title":"GitLab Personal Access Token Setup","text":"<p>To integrate Recce with your GitLab project, you'll need to create a Personal Access Token (PAT) with appropriate permissions.</p>"},{"location":"2-getting-started/gitlab-pat-guide/#token-scope-requirements","title":"Token Scope Requirements","text":"<p>Recce supports two different permission levels depending on your needs:</p> Scope Permissions Features Available <code>api</code> Full API access (read and write) \u2022 View and track merge requests\u2022 Receive generated summaries and notes on MRs from Recce\u2022 Full integration capabilities <code>read_api</code> Read-only API access \u2022 View and track merge requests\u2022 Cannot receive generated summaries and notes on MRs from Recce <p>Important: Choose the Right Scope</p> <p>If you want Recce to automatically post validation summaries and notes directly to your merge requests, you must use the <code>api</code> scope. The <code>read_api</code> scope only allows Recce to read merge request information but cannot write comments or summaries back to GitLab.</p>"},{"location":"2-getting-started/gitlab-pat-guide/#how-to-create-a-personal-access-token","title":"How to Create a Personal Access Token","text":"<p>Follow these steps to create a Personal Access Token in GitLab:</p> <ol> <li> <p>Navigate to Personal Access Token Settings in GitLab</p> </li> <li> <p>Create New Token</p> <ul> <li>Click Add new token button</li> <li>Enter a descriptive Token name (e.g., \"Recce Integration\")</li> <li>Set an Expiration date</li> </ul> </li> <li> <p>Select Scopes</p> <p>Choose one of the following based on your needs:</p> <p>Option A: Full Integration (Recommended) - \u2705 <code>api</code> scope - This enables Recce to post validation summaries and notes to your merge requests</p> <p>Option B: Read-Only Access - \u2705 <code>read_api</code> scope - \u26a0\ufe0f You will not receive generated PR summaries and notes on your MRs from Recce</p> </li> <li> <p>Generate Token</p> <ul> <li>Click Create personal access token</li> <li>Important: Copy the token immediately - you won't be able to see it again!</li> </ul> </li> <li> <p>Save Token Securely</p> <ul> <li>Store the token in a secure location</li> </ul> </li> </ol>"},{"location":"2-getting-started/gitlab-pat-guide/#using-your-token-with-recce","title":"Using Your Token with Recce","text":"<p>Once you have your Personal Access Token:</p> <ol> <li>Navigate to Recce settings</li> <li>Select GitLab integration</li> <li>Paste your Personal Access Token</li> <li>Complete the connection setup</li> </ol>"},{"location":"2-getting-started/gitlab-pat-guide/#troubleshooting","title":"Troubleshooting","text":"<p>Token not working?</p> <ul> <li>Verify you've selected the correct scope (<code>api</code> or <code>read_api</code>)</li> <li>Check that the token hasn't expired</li> <li>Ensure you have appropriate project permissions (Maintainer or Owner role)</li> </ul> <p>Not receiving summaries on merge requests?</p> <ul> <li>Verify your token uses the <code>api</code> scope (not just <code>read_api</code>)</li> <li>Check that Recce has write permissions to your project</li> </ul> <p>Still having issues?</p> <ul> <li>Please reach out to us on our Discord or via email at <code>help@reccehq.com</code></li> </ul>"},{"location":"2-getting-started/gitlab-pat-guide/#related-documentation","title":"Related Documentation","text":"<ul> <li>Connect Git Provider</li> <li>CI/CD Getting Started</li> </ul>"},{"location":"2-getting-started/installation/","title":"Open Source Setup","text":""},{"location":"2-getting-started/installation/#open-source-setup","title":"Open Source Setup","text":""},{"location":"2-getting-started/installation/#install-open-source","title":"Install Open Source","text":"<p>From within a dbt project directory: </p><pre><code>cd your-dbt-project/  # if you're not already there\npip install -U recce\n</code></pre><p></p>"},{"location":"2-getting-started/installation/#launch","title":"Launch","text":"<p>To start Recce in the current environment: </p><pre><code>recce server\n</code></pre> Launching Recce enables:<p></p> <ul> <li> <p>Lineage clarity: Trace changes down to the column level</p> </li> <li> <p>Query insights: Explore logic and run custom queries</p> </li> <li> <p>Live diffing: Reload and inspect changes as you iterate</p> </li> </ul> <p>Best suited for quick exploration before moving to structured validation using Diff.</p>"},{"location":"2-getting-started/installation/#configure-diff","title":"Configure Diff","text":"<p>To compare changes, Recce needs a baseline. This guide explains the concept of Diff in Recce and how it fits into data validation workflows. Setup steps vary by environment, so this guide focuses on the core ideas rather than copy-paste instructions.</p> <p>For a concrete example, refer to the 5-minute Jaffle Shop tutorial.</p> <p>To configure a comparison in Recce, two components are required:</p>"},{"location":"2-getting-started/installation/#1-artifacts","title":"1. Artifacts","text":"<p>Recce uses dbt artifacts to perform diffs. These files are generated with each dbt run and typically saved in the <code>target/</code> folder.</p> <p>In addition to the current artifacts, a second set is needed to serve as the baseline for comparison. Recce looks for these in the <code>target-base/</code> folder.</p> <ul> <li><code>target/</code> \u2013 Artifacts from the current development environment</li> <li><code>target-base/</code> \u2013 Artifacts from a baseline environment (e.g., production)</li> </ul> <p>For most setups, retrieve the existing artifacts that generated from the main branch (usually from a CI run or build cache) and save them into a <code>target-base/</code> folder.</p>"},{"location":"2-getting-started/installation/#2-schemas","title":"2. Schemas","text":"<p>Recce also compares the actual query results between two dbt environments, each pointing to a different schema. This allows validation beyond metadata by comparing the data itself.</p> <p>For example:</p> <ul> <li><code>prod</code> schema for production</li> <li><code>dev</code> schema for development</li> </ul> <p>These schemas represent where dbt builds its models.</p> <p>Tip</p> <p>In dbt, an environment typically maps to a schema. To compare data results, separate schemas are required. Learn more in dbt environments.</p> <p>Schemas are typically configured in the <code>profiles.yml</code> file, which defines how dbt connects to the data platform. Both schemas must be accessible for Recce to perform environment-based comparisons.</p> <p>Once both artifacts and schemas are configured, Recce can surface meaningful diffs across logic, metadata, and data.</p>"},{"location":"2-getting-started/installation/#verify-your-setup","title":"Verify your setup","text":"<p>There are two ways to check that your configuration is complete:</p>"},{"location":"2-getting-started/installation/#1-debug-command-cli","title":"1. Debug Command (CLI)","text":"<p>Run <code>recce debug</code> from the command line to verify your setup before launching the server:</p> <pre><code>recce debug\n</code></pre> <p>This command checks artifacts, directories, and warehouse connection, providing detailed feedback on any missing components.</p>"},{"location":"2-getting-started/installation/#2-environment-info-web-ui","title":"2. Environment Info (Web UI)","text":"<p>Use Environment Info in the top-right corner of the Recce web interface to verify your configuration.</p> <p>A correctly configured setup will display two environments:</p> <ul> <li>Base \u2013 the reference schema used for comparison (e.g., production)</li> <li>Current \u2013 the schema for the environment under development (e.g., staging or dev)</li> </ul> <p>This confirms that both the artifacts and schemas are properly connected for diffing. </p>"},{"location":"2-getting-started/installation/#start-with-dbt-cloud","title":"Start with dbt Cloud","text":"<p>dbt Cloud is a hosted service that provides a managed environment for running dbt projects by dbt Labs. This document provides a step-by-step guide to get started Recce with dbt Cloud.</p>"},{"location":"2-getting-started/installation/#prerequisites","title":"Prerequisites","text":"<p>Recce will compare the data models between two environments. That means you need to have two environments in your dbt Cloud project. For example, one for production and another for development. Also, you need to provide the credentials profile for both environments in your <code>profiles.yml</code> file to let Recce access your data warehouse.</p>"},{"location":"2-getting-started/installation/#suggestions-for-setting-up-dbt-cloud","title":"Suggestions for setting up dbt Cloud","text":"<p>To integrate the dbt Cloud with Recce, we suggest to set up two run jobs in your dbt Cloud project.</p>"},{"location":"2-getting-started/installation/#production-run-job","title":"Production Run Job","text":"<p>The production run should be the main branch of your dbt project. You can trigger the dbt Cloud job on every merge to the main branch or schedule it to run at a daily specific time.</p>"},{"location":"2-getting-started/installation/#development-run-job","title":"Development Run Job","text":"<p>The development run should be a separate branch of your dbt project. You can trigger the dbt Cloud job on every merge to the pull-request branch.</p>"},{"location":"2-getting-started/installation/#set-up-dbt-profiles-with-credentials","title":"Set up dbt profiles with credentials","text":"<p>You need to provide the credentials profile for both environments in your <code>profiles.yml</code> file. Here is an example of how your <code>profiles.yml</code> file might look like:</p> <pre><code>dbt-example-project:\n  target: dev\n  outputs:\n    dev:\n      type: snowflake\n      account: \"{{ env_var('SNOWFLAKE_ACCOUNT') }}\"\n\n      # User/password auth\n      user: \"{{ env_var('SNOWFLAKE_USER') | as_text }}\"\n      password: \"{{ env_var('SNOWFLAKE_PASSWORD') | as_text }}\"\n\n      role: DEVELOPER\n      database: cloud_database\n      warehouse: LOAD_WH\n      schema: \"{{ env_var('SNOWFLAKE_SCHEMA') | as_text }}\"\n      threads: 4\n    prod:\n      type: snowflake\n      account: \"{{ env_var('SNOWFLAKE_ACCOUNT') }}\"\n\n      # User/password auth\n      user: \"{{ env_var('SNOWFLAKE_USER') | as_text }}\"\n      password: \"{{ env_var('SNOWFLAKE_PASSWORD') | as_text }}\"\n\n      role: DEVELOPER\n      database: cloud_database\n      warehouse: LOAD_WH\n      schema: PUBLIC\n      threads: 4\n</code></pre>"},{"location":"2-getting-started/installation/#execute-recce-with-dbt-cloud","title":"Execute Recce with dbt Cloud","text":"<p>To compare the data models between two environments, you need to download the dbt Cloud artifacts for both environments. The artifacts include the manifest.json file and the catalog.json file. You can download the artifacts from the dbt Cloud UI.</p>"},{"location":"2-getting-started/installation/#login-to-your-dbt-cloud-account","title":"Login to your dbt Cloud account","text":""},{"location":"2-getting-started/installation/#go-to-the-project-you-want-to-compare","title":"Go to the project you want to compare","text":""},{"location":"2-getting-started/installation/#download-the-dbt-artifacts","title":"Download the dbt artifacts","text":"<p>Download the artifacts from the latest run of both run jobs. You can download the artifacts from the <code>Artifacts</code> tab.</p> <p> </p>"},{"location":"2-getting-started/installation/#set-up-the-dbt-artifacts-folders","title":"Set up the dbt artifacts folders","text":"<p>Extract the downloaded artifacts and keep them in a separate folder. The production artifacts should be in the <code>target-base</code> folder and the development artifacts should be in the <code>target</code> folder.</p> <pre><code>$ tree target target-base\ntarget\n\u251c\u2500\u2500 catalog.json\n\u2514\u2500\u2500 manifest.json\ntarget-base/\n\u251c\u2500\u2500 catalog.json\n\u2514\u2500\u2500 manifest.json\n</code></pre>"},{"location":"2-getting-started/installation/#setup-dbt-project","title":"Setup dbt project","text":"<p>Move the <code>target</code> and <code>target-base</code> folders to the root of your dbt project. You should also have the <code>profiles.yml</code> file in the root of your dbt project with the credentials profile for both environments.</p>"},{"location":"2-getting-started/installation/#launch-recce","title":"Launch Recce","text":"<p>Run the command to compare the data models between the two environments.</p> <pre><code>recce server\n</code></pre>"},{"location":"2-getting-started/oss-vs-cloud/","title":"Choose best for you","text":""},{"location":"2-getting-started/oss-vs-cloud/#choose-whats-best-for-you","title":"Choose what's best for you","text":"<p>Recce offers two ways to validate your data changes: Open Source and Recce Cloud. We recommend starting with Recce Cloud for the easiest setup and team collaboration.</p>"},{"location":"2-getting-started/oss-vs-cloud/#quick-comparison","title":"Quick Comparison","text":"Recce Cloud \u2b50 Recommended Open Source Setup 30 seconds - just sign up 5-10 minutes installation Team Collaboration \u2705 Real-time sharing, checklist sync \u274c Local only PR Integration \u2705 Automatic PR gating \u26a0\ufe0f Manual setup required Exclusive Features \u2705 LLM validation insights, upcoming innovations \u274c Core features only Best For Data teams focused on validation Initial experimentation"},{"location":"2-getting-started/oss-vs-cloud/#choose-recce-cloud-if-you","title":"Choose Recce Cloud If You...","text":"<ul> <li>Want the fastest setup and immediate results</li> <li>Want to focus on data validation, not infrastructure setup</li> <li>Want to do a PoC for your team to evaluate data tools</li> <li>Need team collaboration and stakeholder reviews</li> <li>Want exclusive features like LLM validation insights</li> <li>Want automatic updates with new innovations as they're released</li> <li>Prefer to spend time on data problems, not tool configuration</li> </ul> <p>\ud83d\udc49 Start with Recce Cloud</p>"},{"location":"2-getting-started/oss-vs-cloud/#cloud-plans-overview","title":"Cloud Plans Overview","text":"<ul> <li>Free Plan: All core validation features with zero setup effort</li> <li>Team Plan: Advanced collaboration + LLM validation insights + automated workflows  </li> <li>Enterprise Plan: Full governance + BYOC + SSO + dedicated support</li> </ul> <p>View pricing to learn more</p>"},{"location":"2-getting-started/oss-vs-cloud/#choose-open-source-if-you","title":"Choose Open Source If You...","text":"<ul> <li>Want to experiment locally before team adoption</li> <li>Need to explore Recce without creating accounts first</li> <li>Want to understand the basics before moving to Cloud</li> </ul> <p>\ud83d\udc49 Open Source Setup</p>"},{"location":"2-getting-started/oss-vs-cloud/#whats-next","title":"What's Next","text":"<p>New to Recce? We recommend Cloud for the smoothest experience. You can validate data changes and collaborate with your team within minutes.</p> <p>Already technical? Cloud is still the smart choice. Why spend time on infrastructure when you could focus on data validation? Plus you get exclusive features like LLM insights and automatic updates with new innovations.</p>"},{"location":"2-getting-started/start-free-with-cloud/","title":"Get Started with Recce Cloud","text":""},{"location":"2-getting-started/start-free-with-cloud/#get-started-with-recce-cloud","title":"Get Started with Recce Cloud","text":"<p>This tutorial helps analytics engineers and data engineers set up Recce Cloud to automate data review on pull requests.</p> <p>Get Started </p>"},{"location":"2-getting-started/start-free-with-cloud/#goal","title":"Goal","text":"<p>Reviewing data changes in PRs is error-prone without visibility into downstream impact. After setup, the Recce agent reviews your data changes on every PR\u2014showing what changed and what it affects.</p> <p>To validate changes, Recce compares Base vs Current environments:</p> <ul> <li>Base: models in the main branch (production)</li> <li>Current: models in the PR branch</li> </ul> <p>Recce requires dbt artifacts from both environments. This guide covers:</p> <ul> <li>dbt profile configuration for Base and Current</li> <li>CI/CD workflow setup</li> </ul> <p>For accurate comparisons, both environments should use consistent data ranges. See Best Practices for Preparing Environments for environment strategies.</p> <p>This guide uses Snowflake, GitHub, and GitHub Actions examples, but can be adapted to your configuration. The setup assumes:</p> <ul> <li>Production runs a full daily refresh</li> <li>No pre-configured per-PR environments exist yet</li> <li>Each developer has their own dev environment for local work</li> </ul> <p>We'll configure CI to create isolated, per-PR schemas automatically.</p>"},{"location":"2-getting-started/start-free-with-cloud/#prerequisites","title":"Prerequisites","text":"<ul> <li> Recce Cloud account: free trial at cloud.reccehq.com</li> <li> dbt project in a git repository that runs successfully: your environment can execute <code>dbt build</code> and <code>dbt docs generate</code></li> <li> Repository admin access for setup: required to add workflows and secrets</li> <li> Data warehouse: read access to your warehouse for data diffing</li> </ul>"},{"location":"2-getting-started/start-free-with-cloud/#onboarding-process-overview","title":"Onboarding Process Overview","text":"<p>After signing up, you'll enter the onboarding flow:</p> <ol> <li>Connect data warehouse</li> <li>Connect Git provider</li> <li>Add Recce to CI/CD</li> <li>Merge the CI/CD change</li> </ol>"},{"location":"2-getting-started/start-free-with-cloud/#recce-web-agent-setup-experimental","title":"Recce Web Agent Setup [Experimental]","text":"<p>You can use the Recce Web Agent to help automate your setup. Currently it handles step 3 (Add Recce to CI/CD):</p> <ol> <li>The agent analyzes your repository and CI/CD setup</li> <li>You answer clarifying questions the agent asks about your environment strategy</li> <li>The agent creates a PR with customized workflow files</li> </ol> <p>The agent covers common setups and continues to expand coverage. If your setup isn't supported yet, the agent directs you to the Setup Guide below for manual configuration. Need help? Contact us at support@reccehq.com.</p> <p>Coming soon: The agent will guide you through steps 1\u20133, including warehouse connection, Git connection, and CI/CD configuration.</p>"},{"location":"2-getting-started/start-free-with-cloud/#setup-guide","title":"Setup Guide","text":"<p>This guide explains each onboarding step in detail.</p> <p>First, go to cloud.reccehq.com and create your free account.</p>"},{"location":"2-getting-started/start-free-with-cloud/#1-connect-data-warehouse","title":"1. Connect Data Warehouse","text":"<ol> <li>Select your data warehouse (e.g. Snowflake)</li> <li>Provide your read-only warehouse credentials</li> </ol> <p>Note: This guide uses Snowflake. For supported warehouses, see Connect to Warehouse.</p>"},{"location":"2-getting-started/start-free-with-cloud/#2-connect-git-provider","title":"2. Connect Git Provider","text":"<ol> <li>Click Connect GitHub</li> <li>Authorize the Recce app installation</li> <li>Select the repositories you want to connect</li> </ol> <p>Note: This guide uses GitHub. For GitLab setup, see GitLab Personal Access Token.</p>"},{"location":"2-getting-started/start-free-with-cloud/#3-add-recce-to-cicd","title":"3. Add Recce to CI/CD","text":"<p>This step adds CI/CD workflow files to your repository. The agent creates these automatically. For manual setup, create and merge a PR with the templates below.</p> <p>Note: This guide uses GitHub Actions. For other CI/CD platforms, see Setup CD and Setup CI.</p>"},{"location":"2-getting-started/start-free-with-cloud/#set-up-profileyml","title":"Set Up Profile.yml","text":"<p>The profile.yml file tells your system where to look for the \"base\" and \"current\" builds. We have a sample <code>profile.yml</code> file:</p> <pre><code>&lt;your-dbt-project-name&gt;:\n  target: dev\n  outputs:\n    dev:\n      type: snowflake\n      account: \"{{ env_var('SNOWFLAKE_ACCOUNT') }}\"\n      user: \"{{ env_var('SNOWFLAKE_USER') | as_text }}\"\n      password: \"{{ env_var('SNOWFLAKE_PASSWORD') | as_text }}\"\n      role: DEVELOPER\n      database: cloud_database\n      warehouse: LOAD_WH\n      schema: \"{{ env_var('SNOWFLAKE_SCHEMA') | as_text }}\"\n      threads: 4\n\n    ## Add a new target for CI\n    ci:\n      type: snowflake\n      account: \"{{ env_var('SNOWFLAKE_ACCOUNT') }}\"\n      user: \"{{ env_var('SNOWFLAKE_USER') | as_text }}\"\n      password: \"{{ env_var('SNOWFLAKE_PASSWORD') | as_text }}\"\n      role: DEVELOPER\n      database: cloud_database\n      warehouse: LOAD_WH\n      schema: \"{{ env_var('SNOWFLAKE_SCHEMA') | as_text }}\"\n      threads: 4\n\n    prod:\n      type: snowflake\n      account: \"{{ env_var('SNOWFLAKE_ACCOUNT') }}\"\n      user: \"{{ env_var('SNOWFLAKE_USER') | as_text }}\"\n      password: \"{{ env_var('SNOWFLAKE_PASSWORD') | as_text }}\"\n      role: DEVELOPER\n      database: cloud_database\n      warehouse: LOAD_WH\n      schema: PUBLIC\n      threads: 4\n</code></pre> <p>In this sample:</p> <ol> <li>Base uses the <code>prod</code> target pointing to the <code>PUBLIC</code> schema (your production data)</li> <li>Current uses the <code>ci</code> target with a dynamic schema via <code>env_var('SNOWFLAKE_SCHEMA')</code></li> </ol> <p>The <code>ci</code> target uses an environment variable for the schema name. In <code>pr-workflow.yml</code> below, we set <code>SNOWFLAKE_SCHEMA: \"PR_${{ github.event.pull_request.number }}\"</code> to create isolated environments per PR (e.g., <code>PR_123</code>, <code>PR_456</code>). This isolates each PR's data so multiple PRs can run without conflicts.</p> <p>NOTE: Ensure your data warehouse allows creating schemas dynamically. The CI runner needs write permissions to create PR-specific schemas (e.g., <code>PR_123</code>).</p>"},{"location":"2-getting-started/start-free-with-cloud/#about-secrets","title":"About Secrets","text":"<p>The workflows use two types of secrets:</p> <ul> <li><code>GITHUB_TOKEN</code>: automatically provided by GitHub Actions, no configuration needed. This is used by the GitHub integration you just set up to connect the results of the call to Recce.</li> <li>Warehouse credentials: your existing secrets for dbt (e.g., <code>SNOWFLAKE_ACCOUNT</code>, <code>SNOWFLAKE_USER</code>, <code>SNOWFLAKE_PASSWORD</code>). If your dbt project already runs in CI, you have these configured.</li> </ul>"},{"location":"2-getting-started/start-free-with-cloud/#set-up-base-metadata-updates","title":"Set Up Base Metadata Updates","text":"<p>The Base environment should reflect the dbt configuration in the main branch. Example workflow file: <code>base-workflow.yml</code></p> <pre><code>name: Update Base Metadata\non:\n  push:\n    branches: [\"main\"]\n  schedule:\n    - cron: \"0 2 * * *\"\n  workflow_dispatch:\n\nconcurrency:\n  group: ${{ github.workflow }}\n  cancel-in-progress: true\n\njobs:\n  update-base-session:\n    runs-on: ubuntu-latest\n    timeout-minutes: 30\n    permissions:\n      contents: read\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n\n      - name: Setup Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: \"3.11\"\n          cache: \"pip\"\n\n      - name: Install dependencies\n        run: pip install -r requirements.txt\n\n      - name: Prepare dbt artifacts\n        run: |\n          dbt deps\n          dbt build --target prod\n          dbt docs generate --target prod\n        env:\n          DBT_ENV_SECRET_KEY: ${{ secrets.DBT_ENV_SECRET_KEY }}\n          SNOWFLAKE_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}\n          SNOWFLAKE_USER: ${{ secrets.SNOWFLAKE_USER }}\n          SNOWFLAKE_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}\n          SNOWFLAKE_DATABASE: ${{ secrets.SNOWFLAKE_DATABASE }}\n          SNOWFLAKE_WAREHOUSE: ${{ secrets.SNOWFLAKE_WAREHOUSE }}\n\n      ## Add this part\n      - name: Upload to Recce Cloud\n        run: |\n          pip install recce-cloud\n          recce-cloud upload --type prod\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n</code></pre> <p>This sample workflow:</p> <ul> <li>Runs once a day</li> <li>Installs Python 3.11 and the contents of <code>requirements.txt</code>, and recce-cloud</li> <li>Calls <code>dbt docs generate</code> to generate artifacts</li> <li>Calls <code>recce-cloud upload --type prod</code> to upload the Base metadata, using <code>GITHUB_TOKEN</code> for authentication</li> </ul> <p>To integrate into your own configuration, ensure your workflow includes the bolded steps.</p>"},{"location":"2-getting-started/start-free-with-cloud/#set-up-current-metadata-updates","title":"Set Up Current Metadata Updates","text":"<p>The Current environment should reflect the dbt configuration in the PR branch. Recce provides an example workflow file: <code>pr-workflow.yml</code></p> <pre><code>name: Validate PR Changes\non:\n  pull_request:\n    branches: [\"main\"]\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.ref }}\n  cancel-in-progress: true\n\njobs:\n  validate-changes:\n    runs-on: ubuntu-latest\n    timeout-minutes: 45\n    permissions:\n      contents: read\n      pull-requests: write\n    steps:\n      - name: Checkout PR branch\n        uses: actions/checkout@v4\n        with:\n          fetch-depth: 2\n\n      - name: Setup Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: \"3.11\"\n          cache: \"pip\"\n\n      - name: Install dependencies\n        run: pip install -r requirements.txt\n\n      - name: Build current branch artifacts\n        run: |\n          dbt deps\n          dbt build --target ci\n          dbt docs generate --target ci\n        env:\n          DBT_ENV_SECRET_KEY: ${{ secrets.DBT_ENV_SECRET_KEY }}\n          SNOWFLAKE_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}\n          SNOWFLAKE_USER: ${{ secrets.SNOWFLAKE_USER }}\n          SNOWFLAKE_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}\n          SNOWFLAKE_DATABASE: ${{ secrets.SNOWFLAKE_DATABASE }}\n          SNOWFLAKE_WAREHOUSE: ${{ secrets.SNOWFLAKE_WAREHOUSE }}\n          SNOWFLAKE_SCHEMA: \"PR_${{ github.event.pull_request.number }}\"\n\n      - name: Upload to Recce Cloud\n        run: |\n          pip install recce-cloud\n          recce-cloud upload\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n</code></pre> <p>This sample workflow:</p> <ul> <li>Runs on every PR targeting main</li> <li>Installs Python 3.11, dependencies from <code>requirements.txt</code>, and recce-cloud</li> <li>Creates a per-PR schema (<code>PR_123</code>, <code>PR_456</code>, etc.) using the dynamic <code>SNOWFLAKE_SCHEMA</code> environment variable\u2014this isolates each PR's data so multiple PRs can run simultaneously without conflicts</li> <li>Calls <code>dbt docs generate --target ci</code> to generate artifacts for the PR branch</li> <li>Calls <code>recce-cloud upload</code> to upload the Current metadata, using <code>GITHUB_TOKEN</code> for authentication</li> </ul> <p>To integrate into your own configuration, ensure your workflow includes the bolded steps.</p>"},{"location":"2-getting-started/start-free-with-cloud/#4-merge-the-cicd-change","title":"4. Merge the CI/CD change","text":"<p>Merge the PR containing the workflow files. After merging:</p> <ul> <li>The Base workflow automatically uploads your Base to Recce Cloud</li> <li>The Current workflow is ready to validate future PRs</li> </ul> <p>In Recce Cloud, verify you see:</p> <ul> <li>GitHub Integration: Connected</li> <li>Warehouse Connection: Connected</li> <li>Production Metadata: Updated automatically</li> <li>PR Sessions: all open PRs appear in the list. Only PRs with uploaded metadata can be launched for review.</li> </ul> <p></p>"},{"location":"2-getting-started/start-free-with-cloud/#5-final-steps","title":"5. Final Steps","text":"<p>You can now:</p> <ul> <li>See data review summaries in PR comments</li> <li>Launch Recce instance to visualize changes</li> <li>Review downstream impacts before merging</li> </ul>"},{"location":"2-getting-started/start-free-with-cloud/#verification-checklist","title":"Verification Checklist","text":"<ul> <li> Base workflow: Trigger manually, check Base metadata appears in Recce Cloud</li> <li> Current workflow: Create a test PR, verify PR session appears</li> <li> Data diff: Open PR session, run Row Count Diff</li> </ul>"},{"location":"2-getting-started/start-free-with-cloud/#troubleshooting","title":"Troubleshooting","text":"Issue Solution Authentication errors Confirm repository is connected in Recce Cloud settings Push to main blocked Check branch protection rules Secret names don't match Update template to use your existing secret names Workflow fails Check secrets are configured correctly Artifacts missing Ensure <code>dbt docs generate</code> completes before upload Warehouse connection fails Check IP whitelisting; add GitHub Actions IP ranges"},{"location":"2-getting-started/start-free-with-cloud/#related-resources","title":"Related Resources","text":"<ul> <li>CI/CD Getting Started</li> <li>Setup CD</li> <li>Setup CI</li> <li>Best Practices for Preparing Environments</li> </ul>"},{"location":"3-visualized-change/code-change/","title":"Code Change","text":""},{"location":"3-visualized-change/code-change/#code-change","title":"Code Change","text":"<p>The Code Change feature allows you to compare the SQL code changes between your current branch and the base branch, helping you understand exactly what has been modified in your dbt models.</p>"},{"location":"3-visualized-change/code-change/#viewing-code-change","title":"Viewing Code Change","text":"<p>When you identify a modified model in the Lineage Diff, you can examine the specific code changes to understand the nature of the modifications.</p>"},{"location":"3-visualized-change/code-change/#opening-code-change","title":"Opening Code Change","text":"<p>To view the code changes for a model:</p> <ol> <li>Click on any modified (orange) model node in the lineage view</li> <li>In the node details panel that opens, navigate to the Code tab</li> <li>The code diff will display showing the changes between branches</li> </ol> <p> </p> Viewing code changes for a modified model"},{"location":"3-visualized-change/code-change/#understanding-the-code-diff","title":"Understanding the Code Diff","text":"<p>The code diff uses standard diff formatting to highlight changes:</p> <ul> <li>Red lines (with <code>-</code> prefix) show code that was removed</li> <li>Green lines (with <code>+</code> prefix) show code that was added  </li> <li>Unchanged lines appear in normal formatting for context</li> </ul> <p>This visual comparison makes it easy to identify: - New columns or transformations - Modified business logic - Changes to joins or filters - Updated column names or data types</p>"},{"location":"3-visualized-change/code-change/#full-screen-view","title":"Full Screen View","text":"<p>For complex changes or detailed review, you can expand the code diff to full screen:</p> <ol> <li>Click the expand button in the top-right corner of the code diff panel</li> <li>Review the changes in the larger view for better readability</li> <li>Use this view when conducting thorough code reviews or sharing changes with team members</li> </ol> <p> </p> Full-screen view for detailed code review"},{"location":"3-visualized-change/code-change/#why-code-diff-matters","title":"Why Code Diff Matters","text":"<p>Understanding code changes is essential for:</p> <ul> <li>Impact Assessment: Determining if changes affect downstream models or reports</li> <li>Code Review: Validating that modifications align with business requirements  </li> <li>Collaboration: Clearly communicating what changed to stakeholders</li> <li>Quality Assurance: Ensuring changes don't introduce errors or break existing logic</li> </ul>"},{"location":"3-visualized-change/code-change/#next-steps","title":"Next Steps","text":"<p>After reviewing code changes, you can:</p> <ul> <li>Examine the impact radius to see which downstream models are affected</li> <li>Run data diffs to validate that the changes produce expected results</li> <li>Add your findings to the collaboration checklist for team review</li> </ul> <p>Best Practice</p> <p>Always review code changes alongside data validation checks to ensure your modifications produce the expected results and don't break downstream dependencies.</p>"},{"location":"3-visualized-change/column-level-lineage/","title":"Column-Level Lineage","text":"<p>Column-Level Lineage provides visibility into the upstream and downstream relationships of a column.</p> <p>Common use-cases for column-level lineage are:</p> <ol> <li>Source Exploration: During development, column-level lineage helps you understand how a column is derived.</li> <li>Impact Analysis: When modifying the logic of a column, column-level lineage enables you to assess the potential impact across the entire DAG.</li> <li>Root Cause Analysis: Column-level lineage helps identify the possible source of errors by tracing data lineage at the column level.</li> </ol>"},{"location":"3-visualized-change/column-level-lineage/#usage","title":"Usage","text":"<ol> <li> <p>Select a node in the lineage DAG, then click the column you want to view.</p> <p></p> </li> <li> <p>The column-level lineage for the selected column will be displayed.</p> <p></p> </li> <li> <p>To exit column-level lineage view, click the close button in the upper-left corner.</p> <p></p> </li> </ol>"},{"location":"3-visualized-change/column-level-lineage/#transformation-types","title":"Transformation Types","text":"<p>The transformation type is also displayed for each column, which will help you understand how the column was generated or modified.</p> Type Description Pass-through The column is directly selected from the upstream table. Renamed The column is selected from the upstream table but with a different name. Derived The column is created through transformations applied to upstream columns, such as calculations, conditions, functions, or aggregations. Source The column is not derived from any upstream data. It may originate from a seed/source node, literal value or data generation function. Unknown We have no information about the transformation type. This could be due to a parse error or other unknown reason."},{"location":"3-visualized-change/lineage/","title":"Lineage Diff","text":""},{"location":"3-visualized-change/lineage/#understanding-lineage-diff","title":"Understanding Lineage Diff","text":"<p>The Lineage view is Recce's main interface for visualizing and analyzing how your dbt model changes impact your data pipeline. It shows you the potential area of impact from your modifications, helping you determine which models need further investigation and validation.</p>"},{"location":"3-visualized-change/lineage/#what-is-data-lineage","title":"What is Data Lineage?","text":"<p>Data lineage tracks the flow and transformation of data through your dbt project. In Recce, the lineage graph shows:</p> <ul> <li>Dependencies: Which models depend on others</li> <li>Change Impact: How modifications ripple through your pipeline</li> <li>Data Flow: The path data takes from sources to final outputs</li> </ul>"},{"location":"3-visualized-change/lineage/#viewing-the-lineage-graph","title":"Viewing the Lineage Graph","text":"<p>From the Lineage view, you can determine which models to investigate further and perform various data validation checks that serve as proof-of-correctness of your work.</p> <p> </p> Interactive lineage graph showing modified models <p>Getting Started</p> <p>When you first open Recce, the lineage graph automatically loads showing only the models affected by your changes. This focused view helps you quickly understand the impact of your work.</p>"},{"location":"3-visualized-change/lineage/#filter-nodes","title":"Filter Nodes","text":"<p>In the top control bar, you can change the rule to filter the nodes:</p> <ol> <li>Mode:</li> <li>Changed Models: Modified nodes and their downstream + 1st degree of their parents.</li> <li>All: Show all nodes.</li> <li>Package: Filter by dbt package names.</li> <li>Select: Select nodes by node selection.</li> <li>Exclude: Exclude nodes by node selection.</li> </ol>"},{"location":"3-visualized-change/lineage/#select-nodes","title":"Select Nodes","text":"<p>Click a node to select it, or click the Select nodes button in the top-right corner to select multiple nodes for further operations. For detail, see the Multi Nodes Selections section</p>"},{"location":"3-visualized-change/lineage/#row-count-diff","title":"Row Count Diff","text":"<p>A row count diff can be performed on nodes selected using the <code>select</code> and <code>exclude</code> options:</p> <p></p> <p>After selecting nodes, run the row count diff by:</p> <ol> <li>Clicking the 3 dots (...) button in the top-right corner.</li> <li>Clicking Row Count Diff by Selector.</li> </ol>"},{"location":"3-visualized-change/lineage/#understanding-model-nodes","title":"Understanding Model Nodes","text":""},{"location":"3-visualized-change/lineage/#visual-status-indicators","title":"Visual Status Indicators","text":"Example model node with status indicators <p>Models in the lineage graph are color-coded to indicate their status:</p> <ul> <li>Green: Added models (new to your project)</li> <li>Red: Removed models (deleted from your project)</li> <li>Orange: Modified models (changed code or configuration)</li> <li>Gray: Unchanged models (shown for context)</li> </ul>"},{"location":"3-visualized-change/lineage/#change-detection-icons","title":"Change Detection Icons","text":"<p>Each model node displays two icons in the bottom-right corner that indicate detected changes:</p> <ul> <li>Row Count Icon : Shows when row count differences are detected</li> <li>Schema Icon : Shows when column or data type changes are detected</li> </ul> <p>Grayed-out icons indicate no changes were detected in that category.</p> <p> </p> Model with Schema Change detected <p>Row Count Detection</p> <p>The row count icon only appears after you've run a row count diff on that specific model. This helps you track which models you've already validated.</p> <p> </p> Open the node details panel"},{"location":"3-visualized-change/lineage/#investigating-model-changes","title":"Investigating Model Changes","text":""},{"location":"3-visualized-change/lineage/#opening-the-node-details-panel","title":"Opening the Node Details Panel","text":"<p>Click on any model in the lineage graph to open the node details panel. This is your starting point for deeper analysis.</p>"},{"location":"3-visualized-change/lineage/#schema-diff","title":"Schema Diff","text":"<p>Schema diff helps you understand structural changes to your models.</p> <p>Requirements</p> <p>Schema diff requires <code>catalog.json</code> files in both your base and current environments. Make sure to run <code>dbt docs generate</code> in both environments before starting your Recce session.</p>"},{"location":"3-visualized-change/lineage/#viewing-schema-changes","title":"Viewing Schema Changes","text":"<p>Click on a model to view its schema diff in the node details panel.</p> <p> </p> Interactive schema diff showing column changes"},{"location":"3-visualized-change/lineage/#types-of-schema-changes","title":"Types of Schema Changes","text":"<p>Schema diff identifies:</p> <ul> <li>Added columns: New fields in your model (shown in green)</li> <li>Removed columns: Fields that no longer exist (shown in red)</li> <li>Renamed columns: Fields that have changed names (shown with arrows)</li> <li>Data type changes: Modifications to column types</li> </ul> <p> </p> Schema diff showing renamed column"},{"location":"3-visualized-change/lineage/#code-diff","title":"Code Diff","text":"<p>Understanding the code changes helps you analyze the root cause of data differences.</p> <p>From any model's node details panel, you can view the exact code changes that were made. This helps you understand:</p> <ul> <li>What SQL logic was modified</li> <li>How transformations changed</li> <li>Why data differences might be occurring</li> </ul> <p>Learn more about viewing and analyzing code changes in the Code Diff guide.</p>"},{"location":"3-visualized-change/lineage/#node-details","title":"Node Details","text":""},{"location":"3-visualized-change/lineage/#node-details-overview","title":"Node Details Overview","text":"<p>The node details panel provides comprehensive information about the selected model:</p> <p> </p> Node details panel with exploration options <p>From this panel, you can:</p> <ul> <li>View model information: Node type, materialization, and basic metadata</li> <li>Examine changes: See what specifically changed in the model</li> <li>Run validations: Execute pre-built data diffs and custom queries</li> <li>Add to checklist: Document important findings for review</li> </ul>"},{"location":"3-visualized-change/lineage/#available-data-validation-checks","title":"Available Data Validation Checks","text":"<p>Click the \"Explore Change\" button to access pre-built validation checks that save time on writing SQL:</p> <ol> <li>Row Count Diff: Compare the number of rows between environments</li> <li>Profile Diff: Analyze column-level statistics and distributions</li> <li>Value Diff: Identify specific value changes between datasets</li> <li>Top-K Diff: Compare the most common values in your data</li> <li>Histogram Diff: Visualize data distribution changes</li> </ol>"},{"location":"3-visualized-change/lineage/#custom-query-analysis","title":"Custom Query Analysis","text":"<p>Click \"Query\" to open the query interface where you can:</p> <ul> <li>Write custom SQL to investigate changes</li> <li>Run ad-hoc comparisons between environments</li> <li>Validate specific business logic or data quality rules</li> </ul>"},{"location":"3-visualized-change/lineage/#building-your-validation-checklist","title":"Building Your Validation Checklist","text":"<p>As you investigate changes, you can add important findings to your checklist for documentation and collaboration purposes.</p> <p>Collaboration Best Practice</p> <p>Use the checklist feature to document your validation process. This creates a clear record of what you've tested and verified, making it easier for teammates to review your changes.</p>"},{"location":"3-visualized-change/lineage/#next-steps","title":"Next Steps","text":"<p>After reviewing the lineage changes:</p> <ol> <li>Validate: Run data diffs on critical models to verify changes are correct</li> <li>Document: Add key findings to your checklist with clear descriptions</li> <li>Collaborate: Share your analysis with team members for review</li> <li>Integrate: Use Recce's workflow integration to automate validation in your CI/CD process</li> </ol> <p>Ready to dive deeper into specific validation techniques? Explore the Data Diffing section to learn about different ways to validate your changes. </p>"},{"location":"3-visualized-change/multi-models/","title":"Multi-Models","text":""},{"location":"3-visualized-change/multi-models/#multi-models-selection","title":"Multi-Models Selection","text":"<p>Multiple models can be selected in the Lineage DAG. This enables actions to be performed on multiple models at the same time such as Row Count Diff, or Value Diff.</p>"},{"location":"3-visualized-change/multi-models/#select-models-individually","title":"Select Models Individually","text":"<p>To select multiple models individually, click the checkbox on the models you wish to select.</p> <p> </p> Select multiple models individually"},{"location":"3-visualized-change/multi-models/#select-parent-or-child-models","title":"Select Parent or Child models","text":"<p>To select a node and all of its parents or children:</p> <ol> <li>Click the checkbox on the node</li> <li>Right-click the node</li> <li>Click to select either parent or child models</li> </ol> <p> </p> Select a node and its parents or children"},{"location":"3-visualized-change/multi-models/#perform-actions-on-multiple-models","title":"Perform actions on multiple models","text":"<p>After selecting the desired models, use the Actions menu at the top right of the screen to perform diffs or add checks.</p> <p> </p> Perform actions on multiple models"},{"location":"3-visualized-change/multi-models/#example-row-count-diff","title":"Example - Row Count Diff","text":"<p>An example of selecting multiple models to perform a multi-node row count diff:</p> <p> </p> Perform a Row Count Diff on multiple models"},{"location":"3-visualized-change/multi-models/#example-value-diff","title":"Example - Value Diff","text":"<p>An example of selecting multiple models to perform a multi-node Value Diff:</p> <p> </p> Perform a Value Diff on multiple models"},{"location":"3-visualized-change/multi-models/#schema-and-lineage-diff","title":"Schema and Lineage Diff","text":"<p>From the Lineage DAG, click the Actions dropdown menu and click Lineage Diff or Schema Diff from the Add to Checklist section. This will add:</p> <ul> <li>Lineage Diff: The current Lineage view, dependent on your model selection options.</li> <li>Schema Diff: A diff of all models if none are selected, or specific selected models.</li> </ul> <p> </p> Add a Lineage Diff Check or Schema Check via the Actions dropdown menu <p>Recce supports dbt node selection in the lineage diff. This enables you to target specific resources with data checks by selecting or excluding models.</p>"},{"location":"3-visualized-change/multi-models/#supported-syntax-and-methods","title":"Supported syntax and methods","text":"<p>Since Recce uses dbt's built-in node selector, it supports most of the selecting methods. Here are some examples:</p> <ul> <li>Select a node: <code>my_model</code></li> <li>select by tag: <code>tag:nightly</code></li> <li>Select by wildcard: <code>customer*</code></li> <li>Select by graph operators:  <code>my_model+</code>, <code>+my_model</code>, <code>+my_model</code>, <code>1+my_model+</code></li> <li>Select by union: <code>model1 model2</code></li> <li>Select by intersection: <code>stg_invoices+,stg_accounts+</code></li> <li>Select by state: <code>state:modified</code>, <code>state:modified+</code></li> </ul>"},{"location":"3-visualized-change/multi-models/#use-state-method","title":"Use <code>state</code> method","text":"<p>In dbt, you need to specify the <code>--state</code> option in the CLI. In Recce we use the base environment as the state, allowing you to use the selector on the fly.</p>"},{"location":"3-visualized-change/multi-models/#removed-models","title":"Removed models","text":"<p>Another difference is that in dbt, you cannot select removed models. However, in Recce, you can select removed models and also find them using the graph operator. This is a notable distinction from dbt's node selection capabilities.</p>"},{"location":"3-visualized-change/multi-models/#supported-diff","title":"Supported Diff","text":"<p>In addition to lineage diff, other types of diff also support node selection. You can find these features in the ... button in the top right corner. Currently supported node-based diffs include:</p> <ul> <li>Lineage diff</li> <li>Row count diff</li> <li>Schema diff</li> </ul> <p></p>"},{"location":"3-visualized-change/multi-models/#limitation","title":"Limitation","text":"<ul> <li>\"result\" method not supported</li> <li>\"source_status\" method not supported.</li> <li>YAML selectors not supported.</li> </ul>"},{"location":"4-downstream-impacts/breaking-change-analysis/","title":"Breaking Change Analysis","text":"<p>Breaking Change Analysis examines modified models and categorizes changes into three types:</p> <ul> <li>Breaking changes</li> <li>Partial breaking changes</li> <li>Non-breaking changes</li> </ul> <p>It's generally assumed that any modification to a model\u2019s SQL will affect all downstream models. However, not all changes have the same level of impact. For example, formatting adjustments or the addition of a new column should not break downstream dependencies. Breaking change analysis helps you assess whether a change affects downstream models and, if so, to what extent.</p>"},{"location":"4-downstream-impacts/breaking-change-analysis/#usage","title":"Usage","text":"<p>Use the impact radius view to analyze changed and see the impacted downstream.</p>"},{"location":"4-downstream-impacts/breaking-change-analysis/#categories-of-change","title":"Categories of change","text":""},{"location":"4-downstream-impacts/breaking-change-analysis/#non-breaking-change","title":"Non-breaking change","text":"<p>No downstream models are affected. Common cases are adding new columns, comments, or formatting changes that don't alter logic.</p> <p>Example: Add new columns Adding a new column like status doesn't affect models that don't reference it.</p> <pre><code>select\n    user_id,\n    user_name,\n++  status,\nfrom\n    {{ ref(\"orders\") }}\n</code></pre>"},{"location":"4-downstream-impacts/breaking-change-analysis/#partial-breaking-change","title":"Partial breaking change","text":"<p>Only downstream models that reference specific columns are affected. Common cases are removing, renaming, or redefining a column.</p> <p>Example: Removing a column</p> <pre><code>select\n    user_id,\n--  status,\n    order_date,\nfrom\n    {{ ref(\"orders\") }}\n</code></pre> <p>Example: Renaming a column</p> <pre><code>select\n    user_id,\n--  status\n++  order_status\nfrom\n    {{ ref(\"orders\") }}\n</code></pre> <p>Example: Redefining a column </p><pre><code>select\n    user_id,\n--  discount\n++  coalesce(discount, 0) as discount\nfrom\n    {{ ref(\"orders\") }}\n</code></pre><p></p>"},{"location":"4-downstream-impacts/breaking-change-analysis/#breaking-change","title":"Breaking change","text":"<p>All downstream models are affected. Common case are changes adding a filter condition or adding group by columns.</p> <p>Example: Adding a filter condition This may reduce the number of rows, affecting all downstream logic that depends on the original row set.</p> <pre><code>select\n    user_id,\n    order_date\nfrom\n    {{ ref(\"orders\") }}\n++ where status = 'completed'\n</code></pre> <p>Example: Adding a GROUP BY column Changes the granularity of the result set, which can break all dependent models.</p> <pre><code>select\n    user_id,\n++  order_data,\n    count(*) as total_orders\nfrom\n    {{ ref(\"orders\") }}\n-- group by user_id\n++ group by user_id, order_date\n</code></pre>"},{"location":"4-downstream-impacts/breaking-change-analysis/#limitations","title":"Limitations","text":"<p>Our breaking change analysis is intentionally conservative to prioritize safety. As a result, a modified model may be classified as a breaking change when it is actually non-breaking or partial breaking changes. Common cases include:</p> <ol> <li>Logical equivalence in operations, such as changing <code>a + b</code> to <code>b + a</code>.</li> <li>Adding a <code>LEFT JOIN</code> to a table and selecting columns from it. This is often used to enrich the current model with additional dimension table data without affecting existing downstream tables.</li> <li>All modified python models or seeds are treated as breaking change.</li> </ol>"},{"location":"4-downstream-impacts/breaking-change-analysis/#technology","title":"Technology","text":"<p>Breaking Change Analysis is powered by the SQL analysis and AST diff capabilities of SQLGlot to  compare two SQL semantic trees.</p>"},{"location":"4-downstream-impacts/impact-radius/","title":"Impact Radius","text":"<p>Impact Radius helps you analyze changes and identify downstream impacts at the column level.</p> <p>While dbt provides a similar capability using the state selector with <code>state:modified+</code> to identify modified nodes and their downstream dependencies, Recce goes further. By analyzing SQL code directly, Recce enables fine-grained impact radius analysis. It reveals how changes to specific columns can ripple through your data pipeline, helping you prioritize which models\u2014and even which columns\u2014deserve closer attention.</p> state:modified+Impact Radius <p></p> <p></p>"},{"location":"4-downstream-impacts/impact-radius/#usage","title":"Usage","text":""},{"location":"4-downstream-impacts/impact-radius/#show-impact-radius","title":"Show impact radius","text":"<ol> <li> <p>Click the Impact Radius button in the upper-left corner.</p> <p></p> </li> <li> <p>The impact radius will be displayed.</p> <p></p> </li> <li> <p>To exit impact radius view, click the close button in the upper-left corner.</p> <p></p> </li> </ol>"},{"location":"4-downstream-impacts/impact-radius/#show-impact-radius-for-a-single-changed-model","title":"Show impact radius for a single changed model","text":"<ol> <li> <p>Hover over a changed model, then click the target icon or right-click the model and click the Show Impact Radius</p> <p></p> </li> <li> <p>The impact radius for this model will be displayed.</p> <p></p> </li> <li> <p>To exit impact radius view, click the close button in the upper-left corner.</p> <p></p> </li> </ol>"},{"location":"4-downstream-impacts/impact-radius/#impact-radius-of-a-column","title":"Impact Radius of a Column","text":"<p>The right side of the Column-Level Lineage (CLL) graph represents the impact radius of a selected column. This view helps you quickly understand what will be affected if that column changes.</p>"},{"location":"4-downstream-impacts/impact-radius/#what-does-the-impact-radius-include","title":"What does the impact radius include?","text":"<ul> <li>Downstream columns that directly reference the selected column</li> <li>Downstream models that directly depend on the selected column</li> <li>All indirect downstream columns and models that transitively depend on it</li> </ul> <p>This helps you evaluate both the direct and downstream effects of a column change, making it easier to understand its overall impact.</p>"},{"location":"4-downstream-impacts/impact-radius/#example-simplified-model-chain","title":"Example: Simplified Model Chain","text":"<p>Given the following models, here's how changes to <code>stg_orders.status</code> would impact downstream models:</p> <pre><code>-- stg_orders.sql\nselect\n  order_id,\n  customer_id,\n  status,\n  ...\nfrom {{ ref(\"raw_orders\") }}\n\n\n-- orders.sql\nselect\n  order_id,\n  customer_id,\n  status,\n  ...\nfrom {{ ref(\"stg_orders\") }}\n\n\n-- customers.sql\nselect\n  c.customer_id,\n  ...\nfrom {{ ref(\"stg_customers\") }} as c\njoin {{ ref(\"stg_orders\") }} as o\n  on c.customer_id = o.customer_id\nwhere o.status = 'completed'\ngroup by c.customer_id\n\n\n-- customer_segments.sql\nselect\n  customer_id,\n  ...\nfrom {{ ref(\"customers\") }}\n</code></pre> <p></p> <p>The following impact is detected:</p> <ul> <li> <p>orders: This model is partially impacted, as it selects the <code>status</code> column directly from <code>stg_orders</code> but does not apply any transformation or filtering logic. The change is limited to the <code>status</code> column only.</p> </li> <li> <p>customers: This model is fully impacted, because it uses <code>status</code> in a WHERE clause (<code>where o.status = 'completed'</code>). Any change to the logic in <code>stg_orders.status</code> can affect the entire output of the model.</p> </li> <li> <p>customer_segments: This model is indirectly impacted, as it depends on the <code>customers</code> model, which itself is fully impacted. Even though <code>customer_segments</code> does not directly reference <code>status</code>, changes can still propagate downstream via its upstream dependency.</p> </li> </ul>"},{"location":"4-downstream-impacts/impact-radius/#how-it-works","title":"How it works","text":"<p>Two core features power the impact radius analysis:</p> <p>Breaking Change Analysis classifies modified models into three categories:</p> <ul> <li>Breaking changes: Impact all downstream models</li> <li>Non-breaking changes: Do not impact any downstream models</li> <li>Partial breaking changes: Impact only downstream models or columns that depend on the modified columns</li> </ul> <p>Column-level lineage analyzes your model's SQL to identify column-level dependencies:</p> <ul> <li>Which upstream columns are used as filters or grouping keys. If those upstream columns change, the current model is impacted.</li> <li>Which upstream columns a specific column references. If those upstream columns change, the specific column is impacted.</li> </ul>"},{"location":"4-downstream-impacts/impact-radius/#putting-it-together","title":"Putting It Together","text":"<p>With the insights from the two features above, Recce determines the impact radius:</p> <ol> <li>If a model has a breaking change, include all downstream models in the impact radius.</li> <li>If a model has a non-breaking change, include only the downstream columns and models of newly added columns.</li> <li>If a model has a partial breaking change, include the downstream columns and models of added, removed, or modified columns.</li> </ol>"},{"location":"4-downstream-impacts/metadata-first/","title":"Metadata First","text":""},{"location":"4-downstream-impacts/metadata-first/#metadata-first-apporach","title":"Metadata first apporach","text":"<p>dont do data diffing for everything</p>"},{"location":"4-downstream-impacts/transformation-types/","title":"Transformation Types","text":"<p>coming soon. How to use Transformation in Impact Raduis</p>"},{"location":"5-data-diffing/connect-to-warehouse/","title":"Connect to Warehouse","text":""},{"location":"5-data-diffing/connect-to-warehouse/#recce-oss","title":"Recce OSS","text":"<p>Recce OSS supports all warehouses that dbt supports. It uses the same configuration as dbt, simply use your existing dbt profiles to connect to your warehouse. No additional setup required.</p>"},{"location":"5-data-diffing/connect-to-warehouse/#recce-cloud","title":"Recce Cloud","text":"<p>If you use Recce Cloud, here are the warehouse connection settings. We currently support:</p> <ul> <li>Snowflake</li> <li>Databricks</li> <li>BigQuery</li> <li>Redshift</li> </ul> <p>Others are coming in future releases</p>"},{"location":"5-data-diffing/connect-to-warehouse/#security","title":"Security","text":"<p>Recce Cloud protects all warehouse connection config (such as passwords, tokens, and private keys) using envelope encryption with AWS KMS. Credentials are encrypted at rest using AES-256, with encryption keys managed by AWS KMS. Decrypted credentials exist only in memory during connection establishment and are never written to disk. AWS KMS keys rotate automatically every 365 days to maintain security best practices.</p>"},{"location":"5-data-diffing/connect-to-warehouse/#snowflake","title":"Snowflake","text":"<p>We support two authentication methods for Snowflake:</p> <ul> <li>User &amp; Password: Traditional username and password authentication</li> <li>Key Pair: More secure authentication using RSA key pairs</li> </ul>"},{"location":"5-data-diffing/connect-to-warehouse/#common-fields","title":"Common Fields","text":"Field Description Examples <code>account</code> The Snowflake account to connect to <code>xxxxxx.us-central1.gcp</code> <code>database</code> The default database to connect to <code>MY_DB</code> <code>schema</code> The default schema to connect to <code>PUBLIC</code> <code>warehouse</code> The warehouse to use when running queries <code>WH_LOAD</code>"},{"location":"5-data-diffing/connect-to-warehouse/#user-password-authentication","title":"User &amp; Password Authentication","text":"Field Description Examples <code>user</code> The user to log in as <code>MY_USER</code> <code>password</code> The password for the user <code>MY_PASS</code>"},{"location":"5-data-diffing/connect-to-warehouse/#key-pair-authentication","title":"Key Pair Authentication","text":"Field Description Required <code>user</code> The user to log in as Yes <code>private_key</code> Your RSA private key in PEM format or Base64-encoded DER format Yes <code>private_key_passphrase</code> Passphrase for the private key (only required if your private key is encrypted) No <p>For more information on setting up key pair authentication, refer to Snowflake's key pair authentication documentation.</p>"},{"location":"5-data-diffing/connect-to-warehouse/#databricks","title":"Databricks","text":"<p>We support two authentication methods for Databricks:</p> <ul> <li>Token-based: Require Personal Access Token (PAT)</li> <li>OAuth Client-based (M2M): Auto-enabled in every account with expected settings More details here).</li> </ul>"},{"location":"5-data-diffing/connect-to-warehouse/#common-fields_1","title":"Common Fields","text":"Field Description Examples <code>host</code> The hostname of your cluster <code>YOURORG.databrickshost.com</code> <code>http_path</code> The HTTP path to your SQL Warehouse or all-purpose cluster <code>/SQL/YOUR/HTTP/PATH</code> <code>catalog</code> The catalog used to connect to the warehouse. This is optional if you are using Unity Catalog <code>MY_CATALOG</code> <code>schema</code> The default schema to connect to <code>MY_SCHEMA</code>"},{"location":"5-data-diffing/connect-to-warehouse/#token-based-authentication","title":"Token-based Authentication","text":"Field Description Examples <code>token</code> The Personal Access Token (PAT) to connect to Databricks <code>dapiXXXXXXXXXXXXXXXXXXXXXXX</code>"},{"location":"5-data-diffing/connect-to-warehouse/#oauth-client-based-authentication-m2m","title":"OAuth Client-based Authentication (M2M)","text":"Field Description Required <code>auth_type</code> The type of authorization needed to connect to Databricks. Default as <code>oauth</code> Yes <code>client_id</code> The client ID for your Databricks OAuth application Yes <code>client_secret</code> The client secret for your Databricks OAuth application Yes <p>For more information on setting up OAuth Client-based authentication, refer to Databricks's Oauth Client-based authentication documentation.</p>"},{"location":"5-data-diffing/connect-to-warehouse/#bigquery","title":"BigQuery","text":"<p>Important</p> <p>For authentication, we currently provide support for service account JSON only. More details here.</p> Field Description Examples <code>project</code> The GCP project to connect to <code>GCP_PROJECT_ID</code> <code>dataset</code> The default BigQuery dataset to connect to <code>DBT_DATASET_NAME</code> <code>keyfile_json</code> The keyfile generated from your GCP service account to connect to BigQuery <code>keyfile_json: type: xxx project_id: xxx private_key_id: xxx ...</code>"},{"location":"5-data-diffing/connect-to-warehouse/#redshift","title":"Redshift","text":"<p>Important</p> <p>We currently support Database (Password-based authentication) only. More details here.</p> Field Description Examples <code>host</code> Host of your cluster <code>hostname.region.redshift.amazonaws.com</code> <code>user</code> Account username to log into your cluster <code>MY_USER</code> <code>password</code> Password for authentication <code>MY_PASS</code> <code>dbname</code> The default database to connect to <code>MY_DB</code> <code>schema</code> The default schema to connect to <code>MY_SCHEMA</code> <code>port</code> Port for your Redshift environment <code>5439</code>"},{"location":"5-data-diffing/histogram-diff/","title":"Histogram Diff","text":""},{"location":"5-data-diffing/histogram-diff/#histogram-diff","title":"Histogram Diff","text":"<p>Histogram Diff compares the distribution of a numeric column in an overlay histogram chart.</p> <p> </p> Histogram Diff <p>A Histogram Diff can be generated in two ways.</p> <p>Via the Explore Change button menu:</p> <ol> <li>Select the model from the Lineage DAG.</li> <li>Click the <code>Explore Change</code> button.</li> <li>Click <code>Histogram Diff</code>.</li> <li>Select a column to diff.</li> <li>Click <code>Execute</code>.</li> </ol> <p>Via the column options menu:</p> <ol> <li>Select the model from the Lineage DAG.</li> <li>Hover over the column in the Node Details panel.</li> <li>Click the vertical 3 dots <code>...</code></li> <li>Click <code>Histogram Diff</code>.</li> </ol> <p> </p> Generate a Recce Histogram Diff from the column options"},{"location":"5-data-diffing/histogram-diff/#sql-execution","title":"SQL Execution","text":"<p>Histogram Diff generates SQL queries to create distribution histograms for numeric and date columns. The queries use binning strategies to group values and count occurrences in each bin, supporting both integer and floating-point data types.</p> <p>You can review the exact SQL generation functions in the HistogramDiffTask class.</p>"},{"location":"5-data-diffing/mcp-server/","title":"MCP Server","text":"<p>Recce exposes its tools to AI agents, enabling integration with tools like Claude Code. This allows you to interact with Recce analysis through natural language queries directly in your Claude Code sessions.</p>"},{"location":"5-data-diffing/mcp-server/#installation","title":"Installation","text":"<p>Install Recce with the MCP extra dependency:</p> <pre><code>pip install 'recce[mcp]'\n</code></pre>"},{"location":"5-data-diffing/mcp-server/#method-1-mcp-server-stdio","title":"Method 1: MCP Server (Stdio)","text":"<p>Configure Recce as an MCP server with stdio transport. Claude Code will automatically launch the MCP server when you start a session.</p> <ol> <li> <p>Configure the MCP server for your dbt project:</p> <pre><code>cd my-dbt-project/\nclaude mcp add --scope project recce -- recce mcp-server\n</code></pre> </li> <li> <p>Run Claude Code</p> <pre><code>claude\n</code></pre> <p>Verify the connection by running the <code>/mcp</code> command in Claude Code:</p> <pre><code>&gt; /mcp\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 Manage MCP servers                                         \u2502\n\u2502                                                            \u2502\n\u2502 \u276f 1. recce            \u2714 connected \u00b7 Enter to view details  \u2502\n</code></pre> </li> <li> <p>Ask Claude Code about your changes</p> <pre><code>&gt; Understand changes from Recce.\n</code></pre> </li> </ol>"},{"location":"5-data-diffing/mcp-server/#method-2-mcp-server-sse","title":"Method 2: MCP Server (SSE)","text":"<p>Alternatively, launch a standalone MCP server that Claude Code connects to via HTTP-SSE. This requires running the server in a separate terminal.</p> <ol> <li> <p>Start the standalone MCP server:</p> <pre><code>cd my-dbt-project/\nrecce mcp-server --sse\n</code></pre> </li> <li> <p>In a separate terminal, configure the MCP server for your dbt project:</p> <pre><code>cd my-dbt-project/\nclaude mcp add --transport sse --scope project recce http://localhost:8000/sse\n</code></pre> </li> <li> <p>run Claude Code:</p> <pre><code>claude\n</code></pre> <p>Verify the connection by running the <code>/mcp</code> command in Claude Code:</p> <pre><code>&gt; /mcp\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 Manage MCP servers                                         \u2502\n\u2502                                                            \u2502\n\u2502 \u276f 1. recce            \u2714 connected \u00b7 Enter to view details  \u2502\n</code></pre> </li> <li> <p>Ask Claude Code about your changes:</p> <pre><code>&gt; Understand changes from Recce.\n</code></pre> </li> </ol>"},{"location":"5-data-diffing/profile-diff/","title":"Profile Diff","text":""},{"location":"5-data-diffing/profile-diff/#profile-diff","title":"Profile Diff","text":"<p>Profile Diff compares the basic statistic (e.g. count, distinct count, min, max, average) for each column in models between two environments.</p> <ol> <li>Select the model from the Lineage DAG.</li> <li>Click the <code>Expore Change</code> button.</li> <li>Click <code>Profile Diff</code>.</li> </ol>"},{"location":"5-data-diffing/profile-diff/#sql-execution","title":"SQL Execution","text":"<p>Profile Diff generates SQL queries using Jinja templates to calculate statistical measures for each column in your models. The queries analyze data distribution, null values, uniqueness, and numerical statistics.</p> <p>You can review the exact SQL templates.</p> <p> </p> Profile Diff <p>The Statistics:</p> <ul> <li>Row count</li> <li>Not null proportion</li> <li>Distinct proportion</li> <li>Distinct count</li> <li>Is unique</li> <li>Minimum</li> <li>Maximum</li> <li>Average</li> <li>Median</li> </ul>"},{"location":"5-data-diffing/query/","title":"Query","text":"<p>Query page provides an AdHoc query interface to run arbitrary query or diff the query result between two environments. If you're a dbt user, you can use any dbt macros that are installed in your project.</p>"},{"location":"5-data-diffing/query/#execute-query","title":"Execute Query","text":"<pre><code>select * from {{ ref(\"mymodel\") }}\n</code></pre> <p>Actions</p> <ul> <li>Run: performs query in the current environment.</li> <li>Run Diff: performs the same query in both environments and diffs the results.</li> </ul> <p>Form</p> <ul> <li>Primary key: select the primary key(s) used to compare the query results.</li> </ul> <p>Note</p> <p>If the primary key(s) is specified, the query will occur in the warehouse; otherwise, the query will happen across two environments and the comparison will take place on the client side.</p> <p></p> <p>Tip</p> <p>In Mac, you can use <code>\u2318 Enter</code> to run a query or use <code>\u2318 \u21e7 Enter</code> to run a query diff.</p>"},{"location":"5-data-diffing/query/#query-result","title":"Query Result","text":"<ul> <li>Primary Key: When comparison occurs on the client side, we can select the primary key by clicking the <code>key</code> icon. The primary key columns are used to be identified as the same record for both sides. If no primary key is specified, the records is compared by the row's index.</li> <li>Pinned Column: The pinned column would show first in the column list.</li> <li>Changed Only: By selecting the Changed only, we can show only the changed rows and columns. The pinned columns are always shown even they are not changed.</li> </ul>"},{"location":"5-data-diffing/query/#shortcut-to-query-a-model","title":"Shortcut to query a model","text":"<ol> <li>In the lineage page, select a model</li> <li>Click the Query button</li> <li>Then the query page is shown and filled with the query for this model</li> </ol>"},{"location":"5-data-diffing/query/#add-to-checklist","title":"Add to Checklist","text":"<p>Click the <code>+</code> button in the result pane, then you can add the query result to the checklist.</p>"},{"location":"5-data-diffing/query/#how-query-diff-works","title":"How Query Diff Works","text":"<p>In the current version, Recce provides two ways to compare the query result between two environments.</p> <p>Query diff occurs in the client side:</p> <p>Without primary keys provided upfront, adhoc queries will compare results on the client side. That is, Recce fetches the first 2,000 rows and compare in the client side. The advantage is it has more flexibility to query sql for no PK, especially when column structures differ or no clear primary key exists. However, the limitation is that we cannot find the mismatched rows in a big query result.</p> <p>Query diff occurs in the warehouse:</p> <p>When primary keys are given, it can perform a query diff in the warehouse. It will only display changed, added, or removed rows. Meaning, if only one record is different among a million, that specific record will be visible. Thus reducing the amount of data transferred.</p> <p>Another similar feature is Value Diff. Value diff is based on a chosen model, so you don't need to write SQL to operate it, though it naturally offers less flexibility. Additionally, value diff can show a summary or actual diff records, whereas query diff only shows the actual diff records.</p>"},{"location":"5-data-diffing/row-count-diff/","title":"Row Count Diff","text":""},{"location":"5-data-diffing/row-count-diff/#row-count-diff","title":"Row Count Diff","text":"<p>Row Count Diff shows the difference in row count between the base and current environments.</p> <ol> <li>Click the model in the Lineage DAG.</li> <li>Click the <code>Explore Change</code> button in the node details panel.</li> <li>Click <code>Row Count Diff</code>.</li> </ol> <p> </p> Row Count Diff - Single model"},{"location":"5-data-diffing/topK-diff/","title":"Top-K Diff","text":""},{"location":"5-data-diffing/topK-diff/#top-k-diff","title":"Top-K Diff","text":"<p>Top-K Diff compares the distribution of a categorical column. The top 10 elements are shown by default, which can be expanded to the top 50 elements.</p> <p> </p> Recce Top-K Diff <p>A Top-K Diff can be generated in two ways.</p> <p>Via the Explore Change button menu:</p> <ol> <li>Select the model from the Lineage DAG.</li> <li>Click the <code>Explore Change</code> button.</li> <li>Click <code>Top-K Diff</code>.</li> <li>Select a column to diff.</li> <li>Click <code>Execute</code>.</li> </ol> <p>Via the column options menu:</p> <ol> <li>Select the model from the Lineage DAG.</li> <li>Hover over the column in the Node Details panel.</li> <li>Click the vertical 3 dots <code>...</code></li> <li>Click <code>Top-K Diff</code>.</li> </ol> <p> </p> Generate a Recce Top-K Diff"},{"location":"5-data-diffing/topK-diff/#sql-execution","title":"SQL Execution","text":"<p>Top-K Diff generates SQL queries using FULL OUTER JOIN to compare the most frequent values in categorical columns between environments. The queries group by column values and count occurrences to identify the top K categories.</p> <p>You can review the exact SQL templates in the TopKDiffTask class.</p>"},{"location":"5-data-diffing/value-diff/","title":"Value Diff","text":"<p>Value Diff shows the matched count and percentage for each column in the table. It uses the primary key(s) to uniquely identify the records between the model in both environments.</p> <p>The primary key (PK) is automatically inferred by the first column with the unique test. If no primary key is detected at least one column is required to be specified as the primary key.</p> <p> </p> Value Diff <ul> <li>Added: Newly added PKs.</li> <li>Removed: Removed PKs.</li> <li>Matched: For a column, the count of matched value of common PKs.</li> <li>Matched %: For a column, the ratio of matched over common PKs.</li> </ul> <p>View mismatched values at the row level by clicking the <code>show mismatched values</code> option on a column name:</p> <p></p>"},{"location":"5-data-diffing/value-diff/#sql-execution","title":"SQL Execution","text":"<p>Value Diff generates SQL queries using Jinja templates to compare data between your base and current environments. The queries perform a FULL OUTER JOIN on primary keys to identify added, removed, and mismatched records.</p> <p>You can review the exact SQL templates in the ValueDiffTask class.</p>"},{"location":"6-collaboration/checklist/","title":"Checklist","text":""},{"location":"6-collaboration/checklist/#whats-checklist","title":"What's Checklist","text":"<p>Save your validation checks to the Recce checklist with a description of your findings.</p> <p>These checks can later be added to your pull request comment as proof-of-correctness for your modeling changes.</p> <p> </p> Checklist"},{"location":"6-collaboration/checklist/#diffs-performed-via-the-explore-change-dropdown-menu","title":"Diffs performed via the Explore Change dropdown menu","text":"<p>For the majority of diffs, which are performed via the Explore Change dropdown menu, the Check can be added by clicking the Add to Checklist button in the results panel:</p> <p> </p> Add a Check by clicking the Add to Checklist button in the diff results panel <p>An example performing a Top-K diff and adding the results to the Checklist:</p> <p> </p> Example adding a Top-K Diff to the Checklist"},{"location":"6-collaboration/checklist/#add-to-checklist","title":"Add to Checklist","text":"<p>The Recce Checklist provides a way to record the results of a data check during change exploration. The purpose of adding Checks to the Checklist is to enable you to:</p> <ul> <li>Save Checks with notes of your interpretation of the data</li> <li>Re-run checks following further data modeling changes</li> <li>Share Checks as part of PR or stakeholder review</li> </ul>"},{"location":"6-collaboration/checklist/#preset-check","title":"Preset Check","text":"<p>Preset checks can be the fixed checks that are generated every time a new Recce instance is initiated.</p>"},{"location":"6-collaboration/invitation/","title":"Invitation","text":""},{"location":"6-collaboration/invitation/#inviting-team-members-to-your-recce-organization","title":"Inviting Team Members to Your Recce Organization","text":"<p>To collaborate effectively within Recce Cloud, you can invite team members to join your organization. Follow these steps to send invitations:</p>"},{"location":"6-collaboration/invitation/#step-1-access-organization-settings","title":"Step 1: Access Organization Settings","text":"<ul> <li>Log in to your Recce Cloud account</li> <li>Navigate to Settings \u2192 Organization from the side panel</li> <li>Alternatively, you can access directly via: <code>https://cloud.reccehq.com/settings#organization</code></li> <li>In the Organization Settings section, select your desired organization</li> </ul>"},{"location":"6-collaboration/invitation/#step-2-invite-members","title":"Step 2: Invite Members","text":"<p>Note</p> <p>Please use the SSO email address if your member uses SSO login.</p> <ul> <li>In the Members section, click the Invite Members button</li> <li>Enter the email addresses of the individuals you wish to invite</li> <li>Select the appropriate role for each invitee based on the roles below:</li> </ul>"},{"location":"6-collaboration/invitation/#organization-roles","title":"Organization Roles","text":"Role Key Responsibilities Permissions ADMIN Full organization management \u2022 Update organization info\u2022 Manage member roles\u2022 Remove members\u2022 Transfer storage regions MEMBER Upload metadata and launch instances \u2022 Upload metadata\u2022 Launch Recce instances\u2022 View organization info and member list\u2022 Leave organization VIEWER Only instance launch \u2022 Launch Recce instances\u2022 View organization info and member list\u2022 Leave organization"},{"location":"6-collaboration/invitation/#step-3-send-invitation","title":"Step 3: Send Invitation","text":"<ul> <li>Click the Send Invitation button to dispatch the invites</li> <li>Each invitee will receive an email with a link to join your organization</li> <li>Logged-in invitees will also see notifications on their home page or can view pending invitations in Settings \u2192 Organization</li> </ul>"},{"location":"6-collaboration/invitation/#for-invited-users","title":"For Invited Users","text":"<p>When you receive an invitation to join a Recce organization, you have several ways to respond:</p>"},{"location":"6-collaboration/invitation/#immediate-response","title":"Immediate Response","text":"<ul> <li>Upon login, you'll see a notification modal with the invitations</li> <li>You can immediately accept or decline the invitations directly from the notification without navigating elsewhere</li> </ul>"},{"location":"6-collaboration/invitation/#managing-invitations-later","title":"Managing Invitations Later","text":"<ul> <li>Navigate to Settings \u2192 Organization in your account</li> <li>View all pending invitations in the \"Pending Invitations\" section</li> <li>Review the organization and role</li> <li>Accept or decline each invitation as needed</li> </ul>"},{"location":"6-collaboration/share/","title":"Share","text":""},{"location":"6-collaboration/share/#share-recce-sessions-securely","title":"Share Recce Sessions Securely","text":"<p>Recce provides two secure methods to share your validation results with team members and stakeholders, ensuring everyone can access the insights they need for informed decision-making.</p>"},{"location":"6-collaboration/share/#sharing-methods-overview","title":"Sharing Methods Overview","text":"Access sharing options from the Share button <p>Choose the sharing method that best fits your collaboration needs:</p> <ol> <li>Copy to Clipboard - Quick screenshot sharing for PR comments and discussions</li> <li>Recce Cloud Sharing - Full interactive session sharing with complete context</li> </ol>"},{"location":"6-collaboration/share/#method-1-copy-to-clipboard","title":"Method 1: Copy to Clipboard","text":"<p>For quick sharing of specific results, use the Copy to Clipboard button found in diff results. This feature captures a screenshot image that you can paste directly into PR comments, Slack messages, or other communication channels.</p> <p> </p> Copy a diff result screenshot to the clipboard and paste to GitHub <p>Browser Compatibility</p> <p>Firefox does not support copying images to the clipboard. Instead, Recce displays a modal where you can download the image locally or right-click to copy the image.</p>"},{"location":"6-collaboration/share/#method-2-recce-cloud-sharing","title":"Method 2: Recce Cloud Sharing","text":"<p>When stakeholders need full context but don't have the environment to run Recce locally, use Recce Cloud sharing. This method creates a read-only link that provides complete access to your validation results.</p>"},{"location":"6-collaboration/share/#benefits-of-recce-cloud-sharing","title":"Benefits of Recce Cloud Sharing","text":"<ul> <li>No Setup Required - Stakeholders access results instantly in their browser</li> <li>Full Context - Complete lineage exploration, query results, and validation checklists</li> <li>Read-Only Access - Secure viewing without ability to modify your work</li> <li>Simple Link Sharing - Share via any communication channel</li> </ul> <p>Access Control</p> <p>Anyone with the shared link can view your Recce session after signing into Recce Cloud. For restricted access requirements, contact our team.</p>"},{"location":"6-collaboration/share/#setting-up-recce-cloud-sharing","title":"Setting Up Recce Cloud Sharing","text":"<p>The first time you share via Recce Cloud, you'll need to associate your local Recce with your cloud account. This one-time setup enables secure hosting of your state files.</p>"},{"location":"6-collaboration/share/#step-1-enable-recce-cloud-connection","title":"Step 1: Enable Recce Cloud Connection","text":"<p>Launch the Recce server and click the Use Recce Cloud button if your local installation isn't already connected to Recce Cloud.</p> <p></p>"},{"location":"6-collaboration/share/#step-2-sign-in-and-grant-access","title":"Step 2: Sign In and Grant Access","text":"<p>After successful login, authorize your local Recce to connect with Recce Cloud. This authorization enables the sharing functionality and secure state file hosting.</p> <p></p>"},{"location":"6-collaboration/share/#step-3-complete-the-setup","title":"Step 3: Complete the Setup","text":"<p>Refresh the Recce page to activate the cloud connection. Once connected, the Share button will be available, allowing you to generate shareable links.</p> <p></p> <p>Alternative Setup Method</p> <p>You can also connect to Recce Cloud using the command line:</p> <pre><code>recce connect-to-cloud\n</code></pre> <p>This command handles the sign-in and authorization process directly from your terminal.</p>"},{"location":"6-collaboration/share/#manual-configuration-advanced","title":"Manual Configuration (Advanced)","text":"<p>For containerized environments or when you prefer manual setup, you can configure the Recce Cloud connection directly using your API token.</p>"},{"location":"6-collaboration/share/#step-1-retrieve-your-api-token","title":"Step 1: Retrieve Your API Token","text":"<p>Sign in to Recce Cloud and copy your API token from the personal settings page.</p> <p></p>"},{"location":"6-collaboration/share/#step-2-configure-local-connection","title":"Step 2: Configure Local Connection","text":"<p>Choose one of the following methods to configure your local Recce:</p>"},{"location":"6-collaboration/share/#option-a-command-line-flag","title":"Option A: Command Line Flag","text":"<p>Launch Recce server with your API token. The token will be saved to your profile for future use:</p> <pre><code>recce server --api-token &lt;your_api_token&gt;\n</code></pre>"},{"location":"6-collaboration/share/#option-b-profile-configuration","title":"Option B: Profile Configuration","text":"<p>Edit your <code>~/.recce/profile.yml</code> file to include the API token:</p> <pre><code>api_token: &lt;your_api_token&gt;\n</code></pre> <p>Configuration File Location</p> <p>Mac/Linux: </p><pre><code>cd ~/.recce\n</code></pre><p></p> <p>Windows: </p><pre><code>cd ~\\.recce\n</code></pre><p></p> <p>Navigate to <code>C:\\Users\\&lt;your_username&gt;\\.recce</code> or use the PowerShell command above.</p>"},{"location":"6-collaboration/share/#command-line-sharing","title":"Command Line Sharing","text":"<p>For automated workflows or when working with existing state files, use the <code>recce share</code> command to generate shareable links directly from the terminal.</p>"},{"location":"6-collaboration/share/#basic-sharing","title":"Basic Sharing","text":"<p>If your Recce is already connected to Recce Cloud:</p> <pre><code>recce share &lt;your_state_file&gt;\n</code></pre>"},{"location":"6-collaboration/share/#sharing-with-api-token","title":"Sharing with API Token","text":"<p>For environments where Recce isn't pre-configured with cloud access:</p> <pre><code>recce share --api-token &lt;your_api_token&gt; &lt;your_state_file&gt;\n</code></pre> <p></p>"},{"location":"6-collaboration/share/#security-best-practices","title":"Security Best Practices","text":"<p>When sharing Recce sessions, consider these security guidelines:</p> <ul> <li>Review Content: Ensure shared sessions don't contain sensitive data before generating links</li> <li>Access Control: Be aware that anyone with the link can view your session after signing in</li> <li>Token Security: Keep your API tokens secure and rotate them periodically</li> <li>Team Communication: Share links through secure channels when possible</li> </ul> <p>For additional security requirements or enterprise features, contact our team to discuss custom access controls.</p>"},{"location":"7-cicd/best-practices-prep-env/","title":"Best Practices for Preparing Environments","text":"<p>Recce is designed to compare two environments in your data project. To use it effectively, it is crucial to prepare environments through CI.</p> <p>However, there are many challenges in preparing environments.</p> <ol> <li>Your source data might be continuously updating</li> <li>Your transformations might be time-consuming</li> <li>The base branch may have other PRs merged at any time</li> <li>The generated environment will leave data in the warehouse, which also needs to be properly managed</li> </ol> <p>This article will not focus on how to use Recce, but rather on how to effectively prepare environments for Recce use.</p>"},{"location":"7-cicd/best-practices-prep-env/#best-practices","title":"Best Practices","text":""},{"location":"7-cicd/best-practices-prep-env/#use-schema-to-manage-your-environments","title":"Use schema to manage your environments","text":"<p>In dbt, you can leverage profiles and targets to specify the credentials for your database connections. By using profiles and dynamically setting the schema, you can direct the transformation results to different schemas, effectively creating separate environments. Here's how you can achieve this using <code>env_var</code> or <code>arg</code> to dynamically change the schema:</p> <ol> <li> <p>Define Your Profile and Target: Your <code>profiles.yml</code> should have different targets that you can switch between. Here\u2019s an example of a <code>profiles.yml</code> file:</p> <pre><code>my_profile:\n  target: dev\n  outputs:\n    dev:\n      type: postgres\n      host: localhost\n      user: db_user\n      password: db_pass\n      port: 5432\n      dbname: my_db\n      schema: \"{{ env_var('DBT_SCHEMA') }}\"\n    prod:\n      type: postgres\n      host: prod_host\n      user: prod_user\n      password: prod_pass\n      port: 5432\n      dbname: prod_db\n      schema: public\n</code></pre> </li> <li> <p>Run dbt with the Specified Schema: Now, when you run dbt commands, the <code>schema</code> setting will dynamically use the value of the <code>DBT_SCHEMA</code> environment variable.</p> <pre><code>DBT_SCHEMA=pr_env dbt run\n</code></pre> </li> <li> <p>Using <code>args</code> in dbt: You can also pass arguments directly in your dbt commands to dynamically set variables. For example:</p> <pre><code>dbt run --vars '{\"schema_name\": \"pr_123\"}'\n</code></pre> <p>And modify your <code>profiles.yml</code> to use this variable:</p> <pre><code>my_profile:\n  target: dev\n  outputs:\n    dev:\n      type: postgres\n      host: localhost\n      user: db_user\n      password: db_pass\n      port: 5432\n      dbname: my_db\n      schema: \"{{ var('schema_name') }}\"\n</code></pre> </li> </ol> <p>This approach allows you to dynamically create different environments by changing the schema on-the-fly. This is particularly useful for creating isolated environments for different PRs or testing scenarios, ensuring that your transformations are scoped to the correct schema and avoiding conflicts between different environments.</p>"},{"location":"7-cicd/best-practices-prep-env/#prepare-single-base-environment-for-all-prs-to-compare","title":"Prepare single base environment for all PRs to compare","text":"<p>Using the production environment as the base environment is a straightforward choice. However, to make Recce more efficient, using the staging environment might be more suitable.</p> <p>This staging environment can have the following characteristics:</p> <ol> <li>Ensure that the transformed results reflect the latest commit of the base branch</li> <li>Use the same source data as the PR environment</li> <li>Use the same transformation logic as the PR environment</li> </ol> <p>The basic principle is that the staging environment's configuration should be as close as possible to the PR environments, except for using a different git commit.</p>"},{"location":"7-cicd/best-practices-prep-env/#prepare-per-pr-environment","title":"Prepare per-PR environment","text":"<p>A moderately sized data project may have multiple branches in development simultaneously. To avoid interference, it is recommended that each PR have its own isolated PR environment. The schema name can be <code>pr_&lt;number&gt;</code></p>"},{"location":"7-cicd/best-practices-prep-env/#reduce-the-update-frequency-of-the-source-data-used-by-both-the-base-and-pr-environments","title":"Reduce the update frequency of the source data used by both the base and PR environments","text":"<p>Some data projects may have source data that updates every hour or even every second. This can result in different transformation outcomes due to varying source data at different times, leading to Recce comparison results lacking discernibility.</p> <p>Currently, some data warehouses support zero-copy clone (snowflake, bigquery, databricks), which allows us to freeze the source data at a specific point in time. Considering updating the source data weekly can significantly reduce the variability in environments caused by source data changes.</p> <p></p>"},{"location":"7-cicd/best-practices-prep-env/#limit-the-data-range-used-in-transformations","title":"Limit the data range used in transformations","text":"<p>Most data is temporal. When preparing the base and PR environments, we can use only the data from the last month. This can greatly reduce the data volume while still verifying correctness.</p> <p>If zero-copy clone for the source data is not supported and the source data continues to update, you can consider excluding the current week's data. This approach can ensure that transformations yield consistent results regardless of when they are executed.</p> <p>For example, you can design the transformation to only use data from the last month, up to Sunday at 00:00. This approach combines the benefits of shorter execution times and reduced data volatility.</p> <p></p> <pre><code>SELECT\n    *\nFROM\n    {{ source('your_source_name', 'orders') }}\n{% if target.name != 'prod' %}\nWHERE\n    order_date &gt;= DATEADD(month, -1, CURRENT_DATE)\n    AND order_date &lt; DATE_TRUNC('week', CURRENT_DATE)\n{% endif %}\n</code></pre>"},{"location":"7-cicd/best-practices-prep-env/#ensure-that-the-base-environment-is-always-up-to-date","title":"Ensure that the base environment is always up-to-date","text":"<p>There are two scenarios that may cause the base environment to be out of date:</p> <ol> <li>New Source Data Changes: If you update your data weekly, ensure that your base environment is updated at least once a week as well.</li> <li>New PRs Merged into base branch: You can trigger a base environment update on merge events to ensure it remains current.</li> </ol>"},{"location":"7-cicd/best-practices-prep-env/#ensure-the-pr-branch-is-in-sync-with-the-base-branch","title":"Ensure the PR branch is in sync with the base branch","text":"<p>If the PR is executed after the base branch has been updated, the comparison with the base environment will mix the changes from the PR with the changes from other PRs merged into the base branch. This results in comparison outcomes that do not accurately reflect the impact of the current PR.</p> <p></p> <p>GitHub can automatically detect whether a PR is in sync. You need to enable this feature in the repository settings. Once enabled, you will see whether the PR is up-to-date directly on the PR page.</p> <p></p> <p>You can also to check if the PR is up-to-date in the CI workflow before preparing the PR environment. Here is an example in GitHub action </p><pre><code>- name: Check if PR is up-to-date\n  if: github.event_name == 'pull_request'\n  run: |\n    git fetch origin main\n    UPSTREAM=${GITHUB_BASE_REF:-'main'}\n    HEAD=${GITHUB_HEAD_REF:-${GITHUB_REF#refs/heads/}}\n    if [ \"$(git rev-list --left-only --count ${HEAD}...origin/${UPSTREAM})\" -eq 0 ]; then\n      echo \"Branch is up-to-date\"\n    else\n      echo \"Branch is not up-to-date\"\n      exit 1\n    fi\n</code></pre><p></p>"},{"location":"7-cicd/best-practices-prep-env/#consider-how-to-obtain-your-artifacts-for-environments","title":"Consider how to obtain your artifacts for environments","text":"<p>Recce relies on the base and current environment artifacts to find the corresponding tables in the data warehouse for comparison. So, the question is how to obtain the artifacts of the environments to be compared.</p> <p>Here are a few methods you can choose:</p> <ol> <li>In CI, upload the generated artifact to the cloud storage (e.g., AWS S3)</li> <li>For dbt Cloud users, you can download artifacts for the latest run of a given job</li> <li>For GitHub Actions users, you can use the GitHub CLI (gh) to download artifacts for the latest run of a given workflow</li> </ol> <p>If the methods mentioned above are too complex, a stateless approach is to directly check out the base branch and run <code>dbt docs generate</code> to generate the artifacts.</p>"},{"location":"7-cicd/best-practices-prep-env/#cleaning-up-pr-environments-on-pr-closed","title":"Cleaning up PR environments on PR closed","text":"<p>As the number of PRs in a project increases, automatically generated environments also grow. To manage this, you can create a workflow that listens for PR close events and performs cleanup actions. Additionally, you can schedule periodic cleanups to remove outdated environments, such as those not used for a week.</p> <p>In dbt, you can use the <code>dbt run-operation</code> command to clear a specific schema corresponding to an environment. This can be especially useful for environments named in a pattern such as <code>pr_{env}</code>.</p> <p>Here\u2019s how you can define a macro to clear an environment schema:</p> <pre><code>{% macro clear_schema(schema_name) %}\n{% set drop_schema_command = \"DROP SCHEMA IF EXISTS \" ~ schema_name ~ \" CASCADE;\" %}\n{% do run_query(drop_schema_command) %}\n{% endmacro %}\n</code></pre> <p>Run the macro</p> <pre><code>dbt run-operation clear_schema --args \"{'schema_name': 'pr_123'}\"\n</code></pre>"},{"location":"7-cicd/best-practices-prep-env/#example","title":"Example","text":"Environments Schema Name When to run # of environments Data range Production <code>public</code> Daily 1 All Staging <code>staging</code> Daily + On Merge 1 1 month, excluding this week PR <code>pr_&lt;number&gt;</code> On Push # of opened PR 1 month, excluding this week <ul> <li>Automate environment generation using GitHub Actions</li> <li>PR Environment will only be generated automatically when the PR is up-to-date</li> <li>Artifacts will be stored under the workflow\u2019s artifacts</li> <li>PR environments are removed on PR closed</li> <li>Use staging environment as the base environment for Recce</li> </ul>"},{"location":"7-cicd/ci-cd-getting-started/","title":"CI/CD Getting Started","text":""},{"location":"7-cicd/ci-cd-getting-started/#cicd-getting-started","title":"CI/CD Getting Started","text":"<p>Automate data validation in your development workflow. Catch data issues before they reach production with continuous integration and delivery built specifically for dbt projects.</p>"},{"location":"7-cicd/ci-cd-getting-started/#what-youll-achieve","title":"What you'll achieve","text":"<p>Set up automated workflows that:</p> <ul> <li>Save time on reviews - Eliminate manual validation steps for every change</li> <li>Run data validations on every pull request/merge request - Run data validation checks automatically when changes are proposed</li> <li>Prevent regressions - Catch data quality issues before they reach production</li> </ul> <p>Note</p> <p>CI/CD automation requires a Cloud Plan. Get started for free here.</p>"},{"location":"7-cicd/ci-cd-getting-started/#what-is-cicd","title":"What is CI/CD?","text":"<p>Recce uses both continuous integration (CI) and continuous delivery (CD) to automate data validation:</p> <p>Continuous Integration (CI)</p> <ul> <li>When: Runs when you open a new or update a Pull Request/Merge Request </li> <li>Purpose: Validates proposed changes against baseline (typically this mean production)</li> <li>Benefit: Catches issues before merge, with results in your PR/MR</li> </ul> <p>Continuous Delivery (CD)</p> <ul> <li>When: Runs after merge to main branch</li> <li>Purpose: Updates baseline artifacts Recce uses to with latest production state</li> <li>Benefit: Ensures future comparisons use current baseline</li> </ul>"},{"location":"7-cicd/ci-cd-getting-started/#what-does-look-like-with-recce","title":"What does look like with Recce?","text":"<p>Both CI and CD workflows follow the same pattern:</p> <ol> <li>Trigger event (merge to main, or PR/MR opened/updated)</li> <li>Generate dbt artifacts (<code>dbt docs generate</code> or external source)</li> <li>Upload to Recce Cloud (automatic via workflow action)</li> <li>Validation results appear in Recce dashboard and PR/MR</li> </ol> <p> </p> Automated validation workflow for pull requests"},{"location":"7-cicd/ci-cd-getting-started/#getting-started-with-your-cicd","title":"Getting Started with your CI/CD","text":"<p>Recce integrates with both GitHub Actions and GitLab CI/CD using the lightweight <code>recce-cloud</code> CLI. If you use another CI/CD platform and are interested in Recce, let us know.</p>"},{"location":"7-cicd/ci-cd-getting-started/#prerequisites","title":"Prerequisites","text":"<p>Before setting up, ensure you have:</p> <ul> <li> Recce Cloud account - Start free trial</li> <li> Repository connected to Recce Cloud - Connect Git Provider</li> <li>For GitLab: Create a Personal Access Token if not already done</li> <li> dbt artifacts - Know how to generate <code>manifest.json</code> and <code>catalog.json</code> from your project</li> </ul>"},{"location":"7-cicd/ci-cd-getting-started/#setup-steps","title":"Setup Steps","text":"<p>Both GitHub and GitLab follow the same simple pattern:</p>"},{"location":"7-cicd/ci-cd-getting-started/#1-setup-cd-auto-update-baseline","title":"1. Setup CD - Auto-update baseline","text":"<p>Setup CD Guide - Configure automatic baseline updates when you merge to main</p> <ul> <li>Updates your production baseline artifacts automatically</li> <li>Runs on merge to main + optional scheduled updates</li> <li>Works with both GitHub Actions and GitLab CI/CD</li> </ul>"},{"location":"7-cicd/ci-cd-getting-started/#2-setup-ci-auto-validate-prsmrs","title":"2. Setup CI - Auto-validate PRs/MRs","text":"<p>Setup CI Guide - Enable automatic validation for every PR/MR</p> <ul> <li>Validates data changes in every pull request or merge request</li> <li>Catches issues before they reach production</li> <li>Works with both GitHub Actions and GitLab CI/CD</li> </ul>"},{"location":"7-cicd/ci-cd-getting-started/#why-this-order","title":"Why This Order?","text":"<p>Start with CD first to establish your baseline (production artifacts), then add CI for PR/MR validation. CI validation compares your PR/MR changes against the baseline created by CD.</p>"},{"location":"7-cicd/ci-cd-getting-started/#next-steps","title":"Next Steps","text":"<ol> <li>Setup CD - Establish automatic baseline updates</li> <li>Setup CI - Enable PR/MR validation</li> <li>Review best practices for environment preparation</li> </ol>"},{"location":"7-cicd/ci-cd-getting-started/#related-workflows","title":"Related workflows","text":"<p>After setting up CI/CD automation, explore these workflow guides:</p> <ul> <li>Development workflow - How to validate data impact during development (pre-PR/MR)</li> <li>PR/MR review workflow - How to collaborate with teammates using Recce in PRs/MRs</li> <li>Preset checks - How to configure automatic validation checks</li> </ul>"},{"location":"7-cicd/pr-mr-summary/","title":"PR/MR Data Review","text":"<p>Recce provides a data review summary for each PR to help you understand changes and their impact. Using state-of-the-art AI agents, it analyzes your PR information and metadata updates to determine what should be validated through data diffing in your data warehouse, then delivers comprehensive insights for informed decision-making.</p> <p>Features</p> <ul> <li>Identify what to validate automatically</li> <li>Run checks and assess their impact</li> <li>Explore changes through data diffing</li> <li>Generate insights to guide merge decisions</li> </ul>"},{"location":"7-cicd/pr-mr-summary/#how-to-generate","title":"How to generate","text":"<ol> <li> <p>Generate automatically whenever metadata is updated: The data review summary is generated automatically whenever a session\u2019s metadata is updated. You can update metadata in two ways:</p> <ul> <li>Run <code>recce-cloud upload</code> (commonly used in CI workflows for pull requests)</li> <li>Update a session's metadata through the web UI</li> </ul> </li> <li> <p>Manually generate from PR/MR Session UI: Click the Data Review button in a PR/MR session.</p> </li> <li> <p>Generate via GitHub PR Comment (GitHub only): Comment <code>/recce</code> on your GitHub PR to generate a new data review summary. The Recce bot responds with status updates.</p> <p></p> <p>Progress Indicators:</p> <ul> <li>\ud83d\udc40 Request received</li> <li>\ud83d\ude80 Summary generating</li> <li>\ud83d\udc4d Summary complete</li> </ul> </li> </ol>"},{"location":"7-cicd/pr-mr-summary/#example","title":"Example","text":""},{"location":"7-cicd/preset-checks/","title":"Preset Checks","text":"<p>In a dbt project, there may be some checks that need to be conducted for every PR. For example, this could be an SQL query, or checking whether an important model has had a schema change.</p> <p>Preset checks can be the fixed checks that are generated every time a new Recce instance is initiated.</p>"},{"location":"7-cicd/preset-checks/#configure-the-preset-check","title":"Configure the Preset Check","text":"<p>To configure the preset checks, add the settings to the recce config file.</p> <ol> <li>Add a check to your checklist     </li> <li>Open the menu for the check and select Get Preset Check Template</li> <li> <p>Copy the yaml config from the dialog     </p> </li> <li> <p>Paste the config into the <code>recce.yml</code> file located at the root of the project:</p> <pre><code># recce.yml\nchecks:\n  - name: Query diff of customers\n    description: |\n      This is the demo preset check.\n\n      Please run the query and paste the screenshot to the PR comment.\n    type: query_diff\n    params:\n      sql_template: select * from {{ ref(\"customers\") }}\n    view_options:\n      primary_keys:\n        - customer_id\n</code></pre> </li> </ol>"},{"location":"7-cicd/preset-checks/#create-the-preset-checks","title":"Create the Preset Checks","text":""},{"location":"7-cicd/preset-checks/#recce-server","title":"Recce Server","text":"<ol> <li>When a new Recce instance is launched, all preset checks are automatically set up, but these checks are not executed at this time     </li> <li>When the Run Query button is pressed, the check will be executed</li> </ol>"},{"location":"7-cicd/preset-checks/#recce-run","title":"Recce Run","text":"<ol> <li>Running <code>recce run</code> executes all preset checks. The default output file is recce_state.json.     <pre><code>$ recce run\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 DBT Artifacts \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nBase:\n    Manifest: 2024-04-10 08:54:41.546402+00:00\n    Catalog:  2024-04-10 08:54:42.251611+00:00\nCurrent:\n    Manifest: 2024-04-22 03:24:11.262489+00:00\n    Catalog:  2024-04-10 06:15:13.813125+00:00\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Preset checks \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n                            Recce Preset Checks\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nStatus      Name                 Type         Execution Time   Failed Reason\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n[Success]   Query of customers   Query Diff   0.10 seconds     N/A\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nThe state file is stored at [recce_state.json]\n</code></pre></li> <li>You can view the check results by launching the recce server.     <pre><code>recce server recce_state.json\n</code></pre></li> </ol>"},{"location":"7-cicd/scenario-ci/","title":"Setup CI in Open Source","text":""},{"location":"7-cicd/scenario-ci/#recce-ci-integration-with-github-action","title":"Recce CI integration with GitHub Action","text":"<p>Recce provides the <code>recce run</code> command for CI/CD pipeline. You can integrate Recce with GitHub Actions (or other CI tools) to compare the data models between two environments when a new pull-request is created. The below image describes the basic architecture.</p> <p></p> <p>The following guide demonstrates how to configure Recce in GitHub Actions.</p>"},{"location":"7-cicd/scenario-ci/#prerequisites","title":"Prerequisites","text":"<p>Before integrating Recce with GitHub Actions, you will need to configure the following items:</p> <ul> <li> <p>Set up two environments in your data warehouse. For example, one for base and another for pull request.</p> </li> <li> <p>Provide the credentials profile for both environments in your <code>profiles.yml</code> so that Recce can access your data warehouse. You can put the credentials in a <code>profiles.yml</code> file, or use environment variables.</p> </li> <li> <p>Set up the data warehouse credentials in your GitHub repository secrets.</p> </li> </ul>"},{"location":"7-cicd/scenario-ci/#set-up-recce-with-github-actions","title":"Set up Recce with GitHub Actions","text":"<p>We suggest setting up two GitHub Actions workflows in your GitHub repository. One for the base environment and another for the PR environment.</p> <ul> <li> <p>Base environment workflow: Triggered on every merge to the <code>main branch</code>. This ensures that base artifacts are readily available for use when a PR is opened.</p> </li> <li> <p>PR environment workflow: Triggered on every push to the <code>pull-request branch</code>. This workflow will compare base models with the current PR environment.</p> </li> </ul>"},{"location":"7-cicd/scenario-ci/#base-workflow-main-branch","title":"Base Workflow (Main Branch)","text":"<p>This workflow will perform the following actions:</p> <ol> <li>Run dbt on the base environment</li> <li>Upload the generated DBT artifacts to GitHub workflow artifacts for later use</li> </ol> <pre><code>name: Recce CI Base Branch\n\non:\n  workflow_dispatch:\n  push:\n    branches:\n      - main\n\nconcurrency:\n  group: recce-ci-base\n  cancel-in-progress: true\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Set up Python\n        uses: actions/setup-python@v2\n        with:\n          python-version: \"3.10.x\"\n\n      - name: Install dependencies\n        run: |\n          pip install -r requirements.txt\n\n      - name: Run DBT\n        run: |\n          dbt deps\n          dbt seed --target ${{ env.DBT_BASE_TARGET }}\n          dbt run --target ${{ env.DBT_BASE_TARGET }}\n          dbt docs generate --target ${{ env.DBT_BASE_TARGET }}\n        env:\n          DBT_BASE_TARGET: \"prod\"\n\n      - name: Upload DBT Artifacts\n        uses: actions/upload-artifact@v4\n        with:\n          name: target\n          path: target/\n</code></pre> <p>Note</p> <p>Please place the above file in <code>.github/workflows/dbt_base.yml</code>. This workflow path will also be used in the next PR workflow. If you place it in a different location, please remember to make the corresponding changes in the next step.</p>"},{"location":"7-cicd/scenario-ci/#pr-workflow-pull-request-branch","title":"PR Workflow (Pull Request Branch)","text":"<p>This workflow will perform the following actions:</p> <ol> <li>Run dbt on the PR environment.</li> <li>Download previously generated base artifacts from base workflow.</li> <li>Use Recce to compare the PR environment with the downloaded base artifacts.</li> </ol> <pre><code>name: Recce CI PR Branch\n\non:\n  pull_request:\n    branches: [main]\n\njobs:\n  check-pull-request:\n    name: Check pull request by Recce CI\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v3\n        with:\n          fetch-depth: 0\n      - name: Merge Base Branch into PR\n        uses: DataRecce/PR-Update@v1\n        with:\n          baseBranch: ${{ github.event.pull_request.base.ref }}\n          autoMerge: false\n      - name: Set up Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: \"3.10.x\"\n      - name: Install dependencies\n        run: |\n          pip install -r requirements.txt\n          pip install recce\n      - name: Prepare dbt Base environment\n        run: |\n          gh repo set-default ${{ github.repository }}\n          base_branch=${{ github.base_ref }}\n          run_id=$(gh run list --workflow ${WORKFLOW_BASE} --branch ${base_branch} --status success --limit 1 --json databaseId --jq '.[0].databaseId')\n          echo \"Download artifacts from run $run_id\"\n          gh run download ${run_id} -n target -D target-base\n        env:\n          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n          WORKFLOW_BASE: \".github/workflows/dbt_base.yml\"\n      - name: Prepare dbt Current environment\n        run: |\n          git checkout ${{ github.event.pull_request.head.sha }}\n          dbt deps\n          dbt seed --target ${{ env.DBT_CURRENT_TARGET}}\n          dbt run --target ${{ env.DBT_CURRENT_TARGET}}\n          dbt docs generate --target ${{ env.DBT_CURRENT_TARGET}}\n        env:\n          DBT_CURRENT_TARGET: \"dev\"\n\n      - name: Run Recce CI\n        run: |\n          recce run --github-pull-request-url ${{ github.event.pull_request.html_url }}\n\n      - name: Upload DBT Artifacts\n        uses: actions/upload-artifact@v4\n        with:\n          name: target\n          path: target/\n\n      - name: Upload Recce State File\n        uses: actions/upload-artifact@v4\n        id: recce-artifact-uploader\n        with:\n          name: recce-state-file\n          path: recce_state.json\n</code></pre>"},{"location":"7-cicd/scenario-ci/#review-the-recce-state-file","title":"Review the Recce State File","text":"<p>Review the downloaded Recce state file with the following command:</p> <pre><code>recce server --review recce_state.json\n</code></pre> <p>In the Recce server <code>--review</code> mode, you can review the comparison results of the data models between the base and current environments. It will contain the row counts of modified data models.   </p>"},{"location":"7-cicd/scenario-dev/","title":"Development Overview","text":"<p>In developing a project with dbt, there are numerous methods available to help you query warehouse data for validation. Recce allows for further comparison with production or a specific baseline environment.</p>"},{"location":"7-cicd/scenario-dev/#development-cycle","title":"Development Cycle","text":"<p>The common development cycle is</p> <ol> <li>Write the code, validate the change, commit your code</li> <li>Push the commits to remote</li> <li>Review the impacts of your changes</li> </ol> <p>Here, I assume your pull request hasn't been marked as \"ready for review\" yet, and you're still in the process of development, verifying correctness on your own. In this scenario, Recce can assist you in conducting this validation.</p>"},{"location":"7-cicd/scenario-dev/#check-the-lineage","title":"Check the Lineage","text":"<p>dbt provides a method to identify modified models using <code>dbt ls -s state:modified+,</code> but this is obviously not usable within dbt docs. While you can determine how many models are affected using this command, you can't visualize these results.</p> <p>In Recce, you can conduct an initial assessment of your impact scope by Lineage diff, which may help you identify potential unintended impacts.</p>"},{"location":"7-cicd/scenario-dev/#validate-the-models-metadata","title":"Validate the Models' Metadata","text":"<p>With lineage diff, you can start from the modified models to confirm your impact. An inexpensive method is to examine the impact scope of the affected models' metadata.</p> <p>Firstly, you can start by examining Schema diff to see if any changes are detected in each model's schema. Sometimes, a change from Integer to Text, or from Decimal to Numeric, may have subtle impacts on your downstream models.</p> <p>Additionally, whether the models with schema changes have only added columns is worth noting, as this might not significantly affect your downstream processes. However, if columns are removed, it's essential to pay special attention to ensure it's the expected outcome.</p> <p>Next, you can examine the Row count diff for the affected models. Typically, row counts are stored in the warehouse's metadata, meaning you can obtain row count information without much cost. This allows you to quickly determine if row counts are the same or if there are significant changes. Common issues may arise from an erroneous join resulting in unexpected data volumes and erroneous outcomes. Row count diff provides a fast method to identify similar errors.</p> <p>Observing each model can help you quickly review schema and row count changes. By using the lineage diff graph, conducting basic checks on schema and row count, you can already gain a basic level of confidence in the changes made during your development process.</p> <p></p>"},{"location":"7-cicd/scenario-dev/#validate-the-columns-summary","title":"Validate the Column's Summary","text":"<p>Apparently, model metadata alone is insufficient. Sometimes, we need to assess the magnitude of impact that the changes currently in development have on the critical Marts models.</p> <p>Recce provides 4 powerful diff tools to compare the data level changes.</p> <ol> <li>Value Diff: You can use value diff to observe the matched percentage for each column.</li> <li>Profile Diff: You can use profile diff to compare basic statistical values for each column, such as count, distinct count, min, max, and average.</li> <li>Histogram Diff: You can use histogram diff to examine the distribution changes of numeric columns.</li> <li>Top-K Diff: You can use top-k diff to analyze distribution changes of categorical columns.</li> </ol> <p>It's important to note that these queries may take longer to execute and require reading larger amounts of data. Please choose the appropriate method based on the data volume of each model.</p>"},{"location":"7-cicd/scenario-dev/#validate-by-adhoc-query","title":"Validate by Adhoc Query","text":"<p>If you want to choose the most flexible method, Query diff is the way to go. You can compare individual records, perform complex operations like where, group by, order by. Or even query multiple models with joins.</p> <p>AdHoc queries also support the use of dbt macros, providing the highest level of flexibility for validation. However, the downside is that you'll need to write the queries yourself.</p>"},{"location":"7-cicd/scenario-dev/#check-driven-development","title":"Check Driven Development","text":"<p>Test Driven Development (TDD) is a common development pattern where you write tests first, then begin development, validating until the tests pass.</p> <p>When developing in dbt, of course, you can implement the TDD process through dbt tests. However, writing tests is not the only method. First, tests require very precise validation logic, and second, sometimes we don't want to impact the original data definitions. In such cases, what we want to verify is that the data doesn't change too much, rather than a specific logic.</p> <p>For example, if we want to make slight adjustments to the definition of \"revenue\". In the concept of TDD, we would consider what the input data is and what the output should be. But more often, what we want to verify is just ensuring that the changes in revenue for each month are within an expected range.</p> <p>In recce, we can a simple query for your validation code</p> <pre><code>SELECT\n    date_trunc('month', order_date) AS month,\n    SUM(amount) AS revenue\nFROM\n    orders\nGROUP BY\n    month\nORDER BY\n    month desc\n</code></pre> <p>Next, you can add this check to your checklist. After modifying your code each time, rerun this check until it meets your requirements.</p>"},{"location":"7-cicd/scenario-dev/#save-your-state","title":"Save Your State","text":"<p>Switching branches is often unavoidable during development. To preserve the current state for future use, save or export the state file. To resume the state, start the Recce server with the state file as an argument:</p> <pre><code>recce server recce_issue_123.json\n</code></pre> <p></p>"},{"location":"7-cicd/scenario-dev/#import-checklist","title":"Import Checklist","text":"<p>You can import a checklist from a state file by following these steps:</p> <ol> <li>Go to the Checklist page</li> <li>Click the Import icon at the top of the checklist</li> <li>Select the state file you want to import</li> </ol> <p>This is particularly useful for preserving your favorite checks across different branches.</p>"},{"location":"7-cicd/scenario-pr-review/","title":"PR Review","text":"<p>When you've finished developing your feature, we should turn the pull request (PR) into ready for review state. At this point, the PR submitter needs to provide the necessary information for the PR reviewer. Some projects may offer a PR template. In the dbt official blog, this article provides an excellent example.</p> <p>Recce at this stage aims to assist the submitter in gathering more information to ensure that the reviewer can merge the pull request (PR) with greater confidence.</p>"},{"location":"7-cicd/scenario-pr-review/#screenshots","title":"Screenshots","text":""},{"location":"7-cicd/scenario-pr-review/#lineage","title":"Lineage","text":"<p>The Lineage DAG is crucial information within a dbt project as it helps us understand the dependencies between models. In dbt docs, it provides lineage diagrams. Usually, we can paste this diagram into the PR comment to help the reviewer understand the latest lineage status.</p> <p></p> <p>However, during PR reviews, we may be more interested in understanding what changes have been made and presenting them through the Lineage DAG. At this point, you can utilize Recce to capture a screenshot of the Lineage diff and embed it within your PR comment.</p> <p></p>"},{"location":"7-cicd/scenario-pr-review/#checks","title":"Checks","text":"<p>Another core feature of Recce is its various checks, which allow us to compare key models with the base environment. The typical workflow is as follows:</p> <ol> <li>Generate the various diffs you need</li> <li>Identify the query and its result that you want to present to the reviewer</li> <li>Add it to the checklist</li> <li>Click the Copy to Clipboard button and paste it in the corresponding position within the PR comment</li> <li>Write a description of your check, including explanations and intentions</li> <li>Click the Copy markdown button     </li> <li>paste it in the corresponding position within the PR comment.     </li> </ol>"},{"location":"7-cicd/scenario-pr-review/#share-the-recce-file","title":"Share the Recce File","text":"<p>If you want the reviewer to access your environment, you can also attach the Recce state file to the PR comment.</p> <p>As a Submitter</p> <ol> <li>Save or export the recce state file</li> <li>Attach the state file into the PR comment</li> </ol> <p>As a Reviewer</p> <ol> <li>Download the state file</li> <li>In your dbt project folder, run this command    <pre><code>recce server --review &lt;recce state file&gt;\n</code></pre></li> </ol> <p>By adding the <code>--review</code> option, the Recce server will use the DBT artifacts from the state file to connect to both the base and the pull request (PR) environments.</p> <p>Note</p> <p>Although the artifacts are from the Recce state, you still need to provide the <code>profiles.yml</code> and <code>dbt_project.yml</code> files so that Recce knows which credentials to use to connect to the data warehouse.</p>"},{"location":"7-cicd/setup-cd/","title":"Setup CD","text":""},{"location":"7-cicd/setup-cd/#setup-cd-auto-update-baseline","title":"Setup CD - Auto-Update Baseline","text":"<p>Set up automatic updates for your Recce Cloud base sessions. Keep your data comparison baseline current every time you merge to main, with no manual work required.</p>"},{"location":"7-cicd/setup-cd/#what-this-does","title":"What This Does","text":"<p>Automated Base Session Management eliminates manual baseline maintenance:</p> <ul> <li>Triggers: Merge to main + scheduled updates + manual runs</li> <li>Action: Auto-update base Recce session with latest production artifacts</li> <li>Benefit: Current comparison baseline for all future PRs/MRs</li> </ul>"},{"location":"7-cicd/setup-cd/#prerequisites","title":"Prerequisites","text":"<p>Before setting up CD, ensure you have:</p> <ul> <li> Recce Cloud account - Start free trial</li> <li> Repository connected to Recce Cloud - Connect Git Provider</li> <li> dbt artifacts - Know how to generate <code>manifest.json</code> and <code>catalog.json</code> from your dbt project</li> </ul>"},{"location":"7-cicd/setup-cd/#setup","title":"Setup","text":""},{"location":"7-cicd/setup-cd/#github-actions","title":"GitHub Actions","text":"<p>Create <code>.github/workflows/base-workflow.yml</code>:</p> <pre><code>name: Update Base Metadata\n\non:\n  push:\n    branches: [\"main\"]\n  schedule:\n    - cron: \"0 2 * * *\"\n  workflow_dispatch:\n\nconcurrency:\n  group: ${{ github.workflow }}\n  cancel-in-progress: true\n\njobs:\n  update-base-session:\n    runs-on: ubuntu-latest\n    timeout-minutes: 30\n    permissions:\n      contents: read\n\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n\n      - name: Setup Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: \"3.11\"\n          cache: \"pip\"\n\n      - name: Install dependencies\n        run: pip install -r requirements.txt\n\n      - name: Prepare dbt artifacts\n        run: |\n          dbt deps\n          dbt build --target prod\n          dbt docs generate --target prod\n        env:\n          SNOWFLAKE_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}\n          SNOWFLAKE_USER: ${{ secrets.SNOWFLAKE_USER }}\n          SNOWFLAKE_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}\n          SNOWFLAKE_DATABASE: ${{ secrets.SNOWFLAKE_DATABASE }}\n          SNOWFLAKE_WAREHOUSE: ${{ secrets.SNOWFLAKE_WAREHOUSE }}\n\n      - name: Upload to Recce Cloud\n        run: |\n          pip install recce-cloud\n          recce-cloud upload --type prod\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n</code></pre> <p>Key points:</p> <ul> <li><code>dbt build</code> and <code>dbt docs generate</code> create the required artifacts (<code>manifest.json</code> and <code>catalog.json</code>)</li> <li><code>recce-cloud upload --type prod</code> uploads the Base metadata to Recce Cloud</li> <li><code>GITHUB_TOKEN</code> authenticates with Recce Cloud</li> </ul>"},{"location":"7-cicd/setup-cd/#gitlab-cicd","title":"GitLab CI/CD","text":"<p>Add to your <code>.gitlab-ci.yml</code>:</p> <pre><code>stages:\n  - build\n  - upload\n\nvariables:\n  DBT_TARGET_PROD: \"prod\"\n\n# Production build - runs on schedule or main branch push\nprod-build:\n  stage: build\n  image: python:3.11-slim\n  script:\n    - pip install -r requirements.txt\n    - dbt deps\n    # Optional: dbt build --target $DBT_TARGET_PROD\n    - dbt docs generate --target $DBT_TARGET_PROD\n  artifacts:\n    paths:\n      - target/\n    expire_in: 7 days\n  rules:\n    - if: $CI_PIPELINE_SOURCE == \"schedule\"\n    - if: $CI_PIPELINE_SOURCE == \"push\" &amp;&amp; $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH\n\n# Upload to Recce Cloud\nrecce-upload-prod:\n  stage: upload\n  image: python:3.11-slim\n  script:\n    - pip install recce-cloud\n    - recce-cloud upload --type prod\n  dependencies:\n    - prod-build\n  rules:\n    - if: $CI_PIPELINE_SOURCE == \"schedule\"\n    - if: $CI_PIPELINE_SOURCE == \"push\" &amp;&amp; $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH\n</code></pre> <p>Key points:</p> <ul> <li>Authentication is automatic via <code>CI_JOB_TOKEN</code></li> <li>Configure schedule in CI/CD \u2192 Schedules (e.g., <code>0 2 * * *</code> for daily at 2 AM UTC)</li> <li><code>recce-cloud upload --type prod</code> tells Recce this is a baseline session</li> </ul>"},{"location":"7-cicd/setup-cd/#platform-comparison","title":"Platform Comparison","text":"Aspect GitHub Actions GitLab CI/CD Config file <code>.github/workflows/base-workflow.yml</code> <code>.gitlab-ci.yml</code> Trigger on merge <code>on: push: branches: [\"main\"]</code> <code>if: $CI_PIPELINE_SOURCE == \"push\" &amp;&amp; $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH</code> Schedule setup In workflow YAML (<code>schedule:</code>) In UI: CI/CD \u2192 Schedules Authentication Explicit (<code>GITHUB_TOKEN</code>) Automatic (<code>CI_JOB_TOKEN</code>) Manual trigger <code>workflow_dispatch:</code> Pipeline run from UI"},{"location":"7-cicd/setup-cd/#verification","title":"Verification","text":""},{"location":"7-cicd/setup-cd/#test-the-workflow","title":"Test the Workflow","text":"<p>GitHub:</p> <ol> <li>Go to Actions tab \u2192 Select \"Update Base Recce Session\"</li> <li>Click Run workflow \u2192 Monitor for completion</li> </ol> <p>GitLab:</p> <ol> <li>Go to CI/CD \u2192 Pipelines \u2192 Click Run pipeline</li> <li>Select main branch \u2192 Monitor for completion</li> </ol>"},{"location":"7-cicd/setup-cd/#verify-success","title":"Verify Success","text":"<p>Look for these indicators:</p> <ul> <li> Workflow/Pipeline completes without errors</li> <li> Base session updated in Recce Cloud</li> </ul> <p>GitHub:</p> <p></p> <p>GitLab:</p> <p></p>"},{"location":"7-cicd/setup-cd/#expected-output","title":"Expected Output","text":"<p>When the upload succeeds, you'll see output like this in your workflow logs:</p> <p>GitHub:</p> <pre><code>\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 CI Environment Detection \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nPlatform: github-actions\nSession Type: prod\nCommit SHA: def456ab...\nSource Branch: main\nRepository: your-org/your-repo\nInfo: Using GITHUB_TOKEN for platform-specific authentication\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Creating/touching session \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nSession ID: abc123-def456-ghi789\nUploading manifest from path \"target/manifest.json\"\nUploading catalog from path \"target/catalog.json\"\nNotifying upload completion...\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Uploaded Successfully \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nUploaded dbt artifacts to Recce Cloud for session ID \"abc123-def456-ghi789\"\nArtifacts from: \"/home/runner/work/your-repo/your-repo/target\"\n</code></pre> <p>GitLab:</p> <pre><code>\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 CI Environment Detection \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nPlatform: gitlab-ci\nSession Type: prod\nCommit SHA: a1b2c3d4...\nSource Branch: main\nRepository: your-org/your-project\nInfo: Using CI_JOB_TOKEN for platform-specific authentication\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Creating/touching session \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nSession ID: abc123-def456-ghi789\nUploading manifest from path \"target/manifest.json\"\nUploading catalog from path \"target/catalog.json\"\nNotifying upload completion...\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Uploaded Successfully \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nUploaded dbt artifacts to Recce Cloud for session ID \"abc123-def456-ghi789\"\nArtifacts from: \"/builds/your-org/your-project/target\"\n</code></pre>"},{"location":"7-cicd/setup-cd/#advanced-options","title":"Advanced Options","text":""},{"location":"7-cicd/setup-cd/#custom-artifact-path","title":"Custom Artifact Path","text":"<p>If your dbt artifacts are in a non-standard location:</p> <pre><code>recce-cloud upload --type prod --target-path custom-target\n</code></pre>"},{"location":"7-cicd/setup-cd/#external-artifact-sources","title":"External Artifact Sources","text":"<p>You can download artifacts from external sources before uploading:</p> <pre><code># GitHub example\n- name: Download from dbt Cloud\n  run: |\n    # Your download logic here\n    # Artifacts should end up in target/ directory\n\n- name: Upload to Recce Cloud\n  run: |\n    pip install recce-cloud\n    recce-cloud upload --type prod\n</code></pre>"},{"location":"7-cicd/setup-cd/#dry-run-testing","title":"Dry Run Testing","text":"<p>Test your configuration without actually uploading:</p> <pre><code>recce-cloud upload --type prod --dry-run\n</code></pre>"},{"location":"7-cicd/setup-cd/#troubleshooting","title":"Troubleshooting","text":""},{"location":"7-cicd/setup-cd/#missing-dbt-artifacts","title":"Missing dbt artifacts","text":"<p>Error: <code>Missing manifest.json</code> or <code>Missing catalog.json</code></p> <p>Solution: Ensure <code>dbt docs generate</code> runs successfully before upload:</p> <p>GitHub:</p> <pre><code>- name: Prepare dbt artifacts\n  run: |\n    dbt deps\n    dbt docs generate --target prod  # Required\n</code></pre> <p>GitLab:</p> <pre><code>prod-build:\n  script:\n    - dbt deps\n    - dbt docs generate --target $DBT_TARGET_PROD # Required\n  artifacts:\n    paths:\n      - target/\n</code></pre>"},{"location":"7-cicd/setup-cd/#authentication-issues","title":"Authentication issues","text":"<p>Error: <code>Failed to create session: 401 Unauthorized</code></p> <p>Solutions:</p> <ol> <li>Verify your repository is connected in Recce Cloud settings</li> <li>For GitHub: Ensure <code>GITHUB_TOKEN</code> is passed explicitly to the upload step and the job has <code>contents: read</code> permission</li> <li>For GitLab: Verify project has GitLab integration configured</li> <li>Check that you've created a Personal Access Token</li> <li>Ensure the token has appropriate scope (<code>api</code> or <code>read_api</code>)</li> <li>Verify the project is connected in Recce Cloud settings</li> </ol>"},{"location":"7-cicd/setup-cd/#upload-failures","title":"Upload failures","text":"<p>Error: <code>Failed to upload manifest/catalog</code></p> <p>Solutions:</p> <ol> <li>Check network connectivity to Recce Cloud</li> <li>Verify artifact files exist in <code>target/</code> directory</li> <li>Review workflow/pipeline logs for detailed error messages</li> <li>For GitLab: Ensure artifacts are passed between jobs:</li> </ol> <pre><code>prod-build:\n  artifacts:\n    paths:\n      - target/ # Must include dbt artifacts\n\nrecce-upload-prod:\n  dependencies:\n    - prod-build # Required to access artifacts\n</code></pre>"},{"location":"7-cicd/setup-cd/#session-not-appearing","title":"Session not appearing","text":"<p>Issue: Upload succeeds but session doesn't appear in Recce Cloud</p> <p>Solutions:</p> <ol> <li>Check you're viewing the correct repository in Recce Cloud</li> <li>Verify you're looking at the production/base sessions (not PR/MR sessions)</li> <li>Check session filters in Recce Cloud (may be hidden by filters)</li> <li>Refresh the Recce Cloud page</li> </ol>"},{"location":"7-cicd/setup-cd/#schedule-not-triggering-gitlab-only","title":"Schedule not triggering (GitLab only)","text":"<p>Issue: Scheduled pipeline doesn't run</p> <p>Solutions:</p> <ol> <li>Verify schedule is Active in CI/CD \u2192 Schedules</li> <li>Check schedule timezone settings (UTC by default)</li> <li>Ensure target branch (<code>main</code>) exists</li> <li>Review project's CI/CD minutes quota</li> <li>Verify schedule owner has appropriate permissions</li> </ol>"},{"location":"7-cicd/setup-cd/#next-steps","title":"Next Steps","text":"<p>Setup CI to automatically validate PR/MR changes against your updated base session. This completes your CI/CD pipeline by adding automated data validation for every pull request or merge request.</p>"},{"location":"7-cicd/setup-ci/","title":"Setup CI","text":""},{"location":"7-cicd/setup-ci/#setup-ci-auto-validate-prsmrs","title":"Setup CI - Auto-Validate PRs/MRs","text":"<p>Automatically validate your data changes in every pull request or merge request using Recce Cloud. Catch data issues before they reach production, with validation results right in your PR/MR.</p>"},{"location":"7-cicd/setup-ci/#what-this-does","title":"What This Does","text":"<p>Automated PR/MR Validation prevents data regressions before merge:</p> <ul> <li>Triggers: PR/MR opened or updated against main</li> <li>Action: Auto-update Recce session for validation</li> <li>Benefit: Automated data validation and comparison visible in your PR/MR</li> </ul>"},{"location":"7-cicd/setup-ci/#prerequisites","title":"Prerequisites","text":"<p>Before setting up CI, ensure you have:</p> <ul> <li> Recce Cloud account - Start free trial</li> <li> Repository connected to Recce Cloud - Connect Git Provider</li> <li> dbt artifacts - Know how to generate <code>manifest.json</code> and <code>catalog.json</code> from your dbt project</li> <li> CD configured - Setup CD to establish baseline for comparisons</li> </ul>"},{"location":"7-cicd/setup-ci/#setup","title":"Setup","text":""},{"location":"7-cicd/setup-ci/#github-actions","title":"GitHub Actions","text":"<p>Create <code>.github/workflows/pr-workflow.yml</code>:</p> <pre><code>name: Validate PR Changes\n\non:\n  pull_request:\n    branches: [\"main\"]\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.ref }}\n  cancel-in-progress: true\n\njobs:\n  validate-changes:\n    runs-on: ubuntu-latest\n    timeout-minutes: 45\n    permissions:\n      contents: read\n      pull-requests: write\n\n    steps:\n      - name: Checkout PR branch\n        uses: actions/checkout@v4\n        with:\n          fetch-depth: 2\n\n      - name: Setup Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: \"3.11\"\n          cache: \"pip\"\n\n      - name: Install dependencies\n        run: pip install -r requirements.txt\n\n      - name: Build current branch artifacts\n        run: |\n          dbt deps\n          dbt build --target ci\n          dbt docs generate --target ci\n        env:\n          SNOWFLAKE_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}\n          SNOWFLAKE_USER: ${{ secrets.SNOWFLAKE_USER }}\n          SNOWFLAKE_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}\n          SNOWFLAKE_DATABASE: ${{ secrets.SNOWFLAKE_DATABASE }}\n          SNOWFLAKE_WAREHOUSE: ${{ secrets.SNOWFLAKE_WAREHOUSE }}\n          SNOWFLAKE_SCHEMA: \"PR_${{ github.event.pull_request.number }}\"\n\n      - name: Upload to Recce Cloud\n        run: |\n          pip install recce-cloud\n          recce-cloud upload\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n</code></pre> <p>Key points:</p> <ul> <li>Creates a per-PR schema (<code>PR_123</code>, <code>PR_456</code>, etc.) using the dynamic <code>SNOWFLAKE_SCHEMA</code> environment variable to isolate each PR's data</li> <li><code>dbt build</code> and <code>dbt docs generate</code> create the required artifacts (<code>manifest.json</code> and <code>catalog.json</code>)</li> <li><code>recce-cloud upload</code> (without <code>--type</code>) auto-detects this is a PR session</li> <li><code>GITHUB_TOKEN</code> authenticates with Recce Cloud</li> </ul>"},{"location":"7-cicd/setup-ci/#gitlab-cicd","title":"GitLab CI/CD","text":"<p>Add to your <code>.gitlab-ci.yml</code>:</p> <pre><code>stages:\n  - build\n  - upload\n\nvariables:\n  DBT_TARGET: \"ci\"\n\n# MR build - runs on merge requests\ndbt-build:\n  stage: build\n  image: python:3.11-slim\n  script:\n    - pip install -r requirements.txt\n    - dbt deps\n    # Optional: dbt build --target $DBT_TARGET\n    - dbt docs generate --target $DBT_TARGET\n  artifacts:\n    paths:\n      - target/\n    expire_in: 1 week\n  rules:\n    - if: $CI_PIPELINE_SOURCE == \"merge_request_event\"\n\n# Upload to Recce Cloud\nrecce-upload:\n  stage: upload\n  image: python:3.11-slim\n  script:\n    - pip install recce-cloud\n    - recce-cloud upload\n  dependencies:\n    - dbt-build\n  rules:\n    - if: $CI_PIPELINE_SOURCE == \"merge_request_event\"\n</code></pre> <p>Key points:</p> <ul> <li>Authentication is automatic via <code>CI_JOB_TOKEN</code></li> <li><code>recce-cloud upload</code> (without <code>--type</code>) auto-detects this is an MR session</li> <li><code>dbt docs generate</code> creates the required <code>manifest.json</code> and <code>catalog.json</code></li> </ul>"},{"location":"7-cicd/setup-ci/#platform-comparison","title":"Platform Comparison","text":"Aspect GitHub Actions GitLab CI/CD Config file <code>.github/workflows/pr-workflow.yml</code> <code>.gitlab-ci.yml</code> Trigger <code>on: pull_request:</code> <code>if: $CI_PIPELINE_SOURCE == \"merge_request_event\"</code> Authentication Explicit (<code>GITHUB_TOKEN</code>) Automatic (<code>CI_JOB_TOKEN</code>) Session type Auto-detected from PR context Auto-detected from MR context Artifact passing Not needed (single job) Use <code>artifacts:</code> + <code>dependencies:</code>"},{"location":"7-cicd/setup-ci/#verification","title":"Verification","text":""},{"location":"7-cicd/setup-ci/#test-with-a-prmr","title":"Test with a PR/MR","text":"<p>GitHub:</p> <ol> <li>Create a test PR with small data changes</li> <li>Check Actions tab for CI workflow execution</li> <li>Verify validation runs successfully</li> </ol> <p>GitLab:</p> <ol> <li>Create a test MR with small data changes</li> <li>Check CI/CD \u2192 Pipelines for workflow execution</li> <li>Verify validation runs successfully</li> </ol>"},{"location":"7-cicd/setup-ci/#verify-success","title":"Verify Success","text":"<p>Look for these indicators:</p> <ul> <li> Workflow/Pipeline completes without errors</li> <li> PR/MR session created in Recce Cloud</li> <li> Session URL appears in workflow/pipeline output</li> </ul> <p>GitHub:</p> <p></p> <p>GitLab:</p> <p></p>"},{"location":"7-cicd/setup-ci/#expected-output","title":"Expected Output","text":"<p>When the upload succeeds, you'll see output like this in your workflow logs:</p> <p>GitHub:</p> <pre><code>\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 CI Environment Detection \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nPlatform: github-actions\nPR Number: 42\nPR URL: https://github.com/your-org/your-repo/pull/42\nSession Type: cr\nCommit SHA: abc123de...\nBase Branch: main\nSource Branch: feature/your-feature\nRepository: your-org/your-repo\nInfo: Using GITHUB_TOKEN for platform-specific authentication\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Creating/touching session \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nSession ID: f8b0f7ca-ea59-411d-abd8-88b80b9f87ad\nUploading manifest from path \"target/manifest.json\"\nUploading catalog from path \"target/catalog.json\"\nNotifying upload completion...\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Uploaded Successfully \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nUploaded dbt artifacts to Recce Cloud for session ID \"f8b0f7ca-ea59-411d-abd8-88b80b9f87ad\"\nArtifacts from: \"/home/runner/work/your-repo/your-repo/target\"\nChange request: https://github.com/your-org/your-repo/pull/42\n</code></pre> <p>GitLab:</p> <pre><code>\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 CI Environment Detection \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nPlatform: gitlab-ci\nMR Number: 4\nMR URL: https://gitlab.com/your-org/your-project/-/merge_requests/4\nSession Type: cr\nCommit SHA: c928e3d5...\nBase Branch: main\nSource Branch: feature/your-feature\nRepository: your-org/your-project\nInfo: Using CI_JOB_TOKEN for platform-specific authentication\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Creating/touching session \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nSession ID: f8b0f7ca-ea59-411d-abd8-88b80b9f87ad\nUploading manifest from path \"target/manifest.json\"\nUploading catalog from path \"target/catalog.json\"\nNotifying upload completion...\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Uploaded Successfully \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nUploaded dbt artifacts to Recce Cloud for session ID \"f8b0f7ca-ea59-411d-abd8-88b80b9f87ad\"\nArtifacts from: \"/builds/your-org/your-project/target\"\nChange request: https://gitlab.com/your-org/your-project/-/merge_requests/4\n</code></pre>"},{"location":"7-cicd/setup-ci/#review-prmr-session","title":"Review PR/MR Session","text":"<p>To analyze the changes in detail:</p> <ol> <li>Go to your Recce Cloud</li> <li>Find the PR/MR session that was created</li> <li>Launch Recce instance to explore data differences</li> </ol>"},{"location":"7-cicd/setup-ci/#advanced-options","title":"Advanced Options","text":""},{"location":"7-cicd/setup-ci/#custom-artifact-path","title":"Custom Artifact Path","text":"<p>If your dbt artifacts are in a non-standard location:</p> <pre><code>recce-cloud upload --target-path custom-target\n</code></pre>"},{"location":"7-cicd/setup-ci/#dry-run-testing","title":"Dry Run Testing","text":"<p>Test your configuration without actually uploading:</p> <pre><code>recce-cloud upload --dry-run\n</code></pre>"},{"location":"7-cicd/setup-ci/#troubleshooting","title":"Troubleshooting","text":"<p>If CI is not working, the issue is likely in your CD setup. Most problems are shared between CI and CD:</p> <p>Common issues:</p> <ul> <li>Missing dbt artifacts</li> <li>Authentication failures</li> <li>Upload errors</li> <li>Sessions not appearing</li> </ul> <p>\u2192 See the Setup CD Troubleshooting section for detailed solutions.</p> <p>CI-specific tip: If CD works but CI doesn't, verify:</p> <ol> <li>PR/MR trigger conditions in your workflow configuration</li> <li>The PR/MR is targeting the correct base branch (usually <code>main</code>)</li> <li>You're looking at PR/MR sessions in Recce Cloud (not production sessions)</li> </ol>"},{"location":"7-cicd/setup-ci/#next-steps","title":"Next Steps","text":"<p>After setting up CI, explore these workflow guides:</p> <ul> <li>PR/MR review workflow - Collaborate with teammates using Recce</li> <li>Preset checks - Configure automatic validation checks</li> <li>Best practices - Environment preparation tips</li> </ul>"},{"location":"8-technical-concepts/configuration/","title":"Configuration","text":"<p>The config file for Recce is located in recce.yml. Currently, only preset checks are configurable.</p>"},{"location":"8-technical-concepts/configuration/#preset-checks","title":"Preset Checks","text":"<p>Preset checks can be generated when executing <code>recce server</code> or <code>recce run</code>.</p> <pre><code># recce.yml\nchecks:\n  - name: Query diff of customers\n    description: |\n        This is the demo preset check.\n\n        Please run the query and paste the screenshot to the PR comment.\n    type: query_diff\n    params:\n        sql_template: select * from {{ ref(\"customers\") }}\n    view_options:\n        primary_keys:\n        - customer_id\n</code></pre> Field Description Type Required <code>name</code> the title of the check string Yes <code>description</code> the description of the check string <code>type</code> the type of the check string Yes <code>params</code> the parameters for running the check object Yes <code>view_options</code> the options for presenting the run result object"},{"location":"8-technical-concepts/configuration/#check-params","title":"Check Params","text":""},{"location":"8-technical-concepts/configuration/#row-count-diff","title":"Row Count Diff","text":"Field Description Type Required <code>node_names</code> List of node names. <code>string[]</code> *1 <code>node_ids</code> List of node ides <code>string[]</code> *1 <code>select</code> The node selection syntax to select. See more <code>string</code> <code>exclude</code> the node selection syntax to exclude. See more <code>string</code> <code>packages</code> The package filter <code>string[]</code> <code>view_mode</code> The quick filter to select changed model and 1st degree of upstream. <code>all</code>, <code>changed_models</code> <p>Notes</p> <p>*1: If <code>node_ids</code> or <code>node_names</code> is specified, it will be used; otherwise, nodes will be selected using the criteria defined by <code>select</code>, <code>exclude</code>, <code>packages</code>, and <code>view_mode</code>.</p> <p>Examples</p> <p>Run row count by node selector </p><pre><code>checks:\n  - name: 'name'\n    description: 'description'\n    type: row_count_diff\n    params:\n       select: state:modified,config.materialized:table\n       exclude: tag:dev \n</code></pre><p></p> <p>Run row count by node names </p><pre><code>checks:\n  - name: 'name'\n    description: 'description'\n    type: row_count_diff\n    params:\n      node_names: ['customers', 'orders']\n</code></pre><p></p>"},{"location":"8-technical-concepts/configuration/#schema-diff","title":"Schema Diff","text":"Field Description Type Required <code>node_id</code> The node id or list of node ids to check. <code>string[]</code> *1 <code>select</code> The node selection syntax to select. See more <code>string</code> <code>exclude</code> the node selection syntax to exclude. See more <code>string</code> <code>packages</code> The package filter <code>string[]</code> <code>view_mode</code> The quick filter to select changed model and 1st degree of upstream. <code>all</code>, <code>changed_models</code> <p>Notes</p> <p>*1: If <code>node_id</code> is specified, it will be used; otherwise, nodes will be selected using the criteria defined by <code>select</code>, <code>exclude</code>, <code>packages</code>, and <code>view_mode</code>.</p> <p>Examples</p> <p>Check schema diff by node selector </p><pre><code>checks:\n  - name: 'name'\n    description: 'description'\n    type: schema_diff\n    params:\n       select: state:modified+\n       exclude: tag:dev \n</code></pre><p></p> <p>Check schema diff by node ides </p><pre><code>checks:\n  - name: 'name'\n    description: 'description'\n    type: row_count_diff\n    params:\n      node_id: model.jaffle_shop.customers\n</code></pre><p></p>"},{"location":"8-technical-concepts/configuration/#lineage-diff","title":"Lineage Diff","text":"Field Description Type Required <code>select</code> The node selection syntax to select. See more <code>string</code> <code>exclude</code> the node selection syntax to exclude. See more <code>string</code> <code>packages</code> The package filter <code>string[]</code> <code>view_mode</code> The quick filter to select changed model and 1st degree of upstream. <code>all</code>, <code>changed_models</code> <p>Examples</p> <pre><code>checks:\n  - name: 'name'\n    description: 'description'\n    type: lineage_diff\n    params:\n       select: state:modified+\n       exclude: tag:dev\n</code></pre>"},{"location":"8-technical-concepts/configuration/#query","title":"Query","text":"Field Description Type Required <code>sql_template</code> The SQL statement, templated using Jinja, to be executed <code>string</code> Yes <p>Examples</p> <pre><code>checks:\n  - name: 'name'\n    description: 'description'\n    type: query\n    params:\n       sql_template: select * from {{ ref(\"customers\") }}\n</code></pre>"},{"location":"8-technical-concepts/configuration/#query-diff","title":"Query Diff","text":"Field Description Type Required <code>sql_template</code> The SQL statement, templated using Jinja, to be executed <code>string</code> Yes <code>base_sql_template</code> The SQL statement to execute in the base environment, if specified. <code>string</code> <code>primary_keys</code> The primary keys used to identify a record. <code>string[]</code> *1 <p>*1: If primary_keys is specified, the query diff is performed in the warehouse. Otherwise, the query result (up to the first 2000 records) is returned, and the diff is executed on the client side.</p> <p>Examples</p> <pre><code>checks:\n  - name: 'name'\n    description: 'description'\n    type: query_diff\n    params:\n      sql_template: select * from {{ ref(\"customers\") }}\n      primary_keys:\n      - customer_id\n</code></pre>"},{"location":"8-technical-concepts/configuration/#value-diff","title":"Value Diff","text":"Field Description Type Required <code>model</code> The name of the model. <code>string</code> Yes <code>primary_key</code> The primary key(s) used to uniquely identify a record. <code>string</code> or <code>string[]</code> Yes <code>columns</code> The list of columns to include in the value diff. <code>string[]</code> <p>Examples</p> <p>Value diff summary </p><pre><code>checks:\n  - name: 'name'\n    description: 'description'\n    type: value_diff\n    params:\n      model: customers\n      primary_key: customer_id\n</code></pre><p></p> <p>Value diff with detailed rows </p><pre><code>checks:\n  - name: 'name'\n    description: 'description'\n    type: value_diff_detail\n    params:\n      model: customers\n      primary_key: customer_id\n</code></pre><p></p>"},{"location":"8-technical-concepts/configuration/#profile-diff","title":"Profile Diff","text":"Field Description Type Required <code>model</code> The name of the model. <code>string</code> Yes <p>Examples </p><pre><code>checks:\n  - name: 'name'\n    description: 'description'\n    type: profile_diff\n    params:\n      model: customers\n</code></pre><p></p>"},{"location":"8-technical-concepts/configuration/#histogram-diff","title":"Histogram Diff","text":"Field Description Type Required <code>model</code> The name of the model. <code>string</code> Yes <code>column_name</code> The name of the column. <code>string</code> Yes <code>column_type</code> The type of the column. <code>string</code> Yes <p>Examples </p><pre><code>checks:\n  - name: 'name'\n    description: 'description'\n    type: histogram_diff\n    params:\n      model: customers\n      column_name: customer_lifetime_value\n      column_type: BIGINT      \n</code></pre><p></p>"},{"location":"8-technical-concepts/configuration/#top-k-diff","title":"Top-K Diff","text":"Field Description Type Required <code>model</code> The name of the model. <code>string</code> Yes <code>column_name</code> The name of the column. <code>string</code> Yes <code>k</code> Specifies the top-k items to include in the result. <code>number</code> (Default 50) <p>Examples </p><pre><code>checks:\n  - name: 'name'\n    description: 'description'\n    type: top_k_diff\n    params:\n      model: customers\n      column_name: customer_lifetime_value\n      k: 50\n</code></pre><p></p>"},{"location":"8-technical-concepts/state-file/","title":"State File","text":""},{"location":"8-technical-concepts/state-file/#introduction","title":"Introduction","text":"<p>The state file represents the serialized state of a Recce instance. It is a JSON-formatted file containing the following information:</p> <ul> <li>Checks: Data from the checks added to the checklist on the Checklist page</li> <li>Runs: Each diff execution in Recce corresponds to a run, similar to a query in a data warehouse. Typically, a single run submits a series of queries to the warehouse and retrieves the final results</li> <li>Environment Artifacts: Includes <code>manifest.json</code> and <code>catalog.json</code> files for both the base and current environments</li> <li>Runtime Information: Metadata such as Git branch details and pull request (PR) information from the CI runner</li> </ul>"},{"location":"8-technical-concepts/state-file/#how-to-save-the-state-file","title":"How to Save the State File","text":"<p>There are multiple ways to save the state file.</p> <ol> <li> <p>Save from the Web UI: Click the Save button at the top of the app. Recce will continuously write updates to the state file, effectively working like an auto-save feature, and persist the state until the Recce instance is closed. The file is saved with the specified filename in the directory where the recce server command is run.</p> </li> <li> <p>Export from the Web UI: Click the Export button located in the top-right corner to download the current Recce state to any location on your machine.    </p> </li> <li> <p>Start Recce from a State File: You can provide a state file as an argument when launching Recce. If the file does not exist, Recce will create a state file and start with an empty state. If the file exists, Recce will load the state and continue working from it.    </p><pre><code>recce server my_recce_state.json\n</code></pre><p></p> </li> </ol>"},{"location":"8-technical-concepts/state-file/#how-to-use-the-state-file","title":"How to Use the State File","text":"<p>The state file can be used in several ways:</p> <ol> <li>Continue the state: Launch Recce with the specified state file.    <pre><code>recce server my_recce_state.json\n</code></pre></li> <li>Review the state: Running Recce with the <code>--review</code> option enables review mode. In this mode, Recce uses the dbt artifacts in the state file instead of those in the <code>target/</code> and <code>target-base/</code> directories. This option is useful for distinguishing between development and review purposes.    <pre><code>recce server --review my_recce_state.json\n</code></pre></li> <li>Import checklist from file: To preserve favorite checks across different branches, you can import a checklist by clicking the Import button at the top of the checklist.</li> <li>Continue the state from <code>recce run</code>: This will execute the checks in the specified state file.    <pre><code>recce run --state-file my_recce_state.json\n</code></pre></li> </ol>"},{"location":"8-technical-concepts/state-file/#scenario-development","title":"Scenario: Development","text":"<p>In the development workflow, the state file acts as a session for developing a feature. It allows you to store checks to verify the diff results against the base environment.</p> <p>Common development workflow:</p> <ol> <li>Run the recce server without a state file.     <pre><code>recce server\n</code></pre></li> <li>Add checks to the checklist.</li> <li>Save the state by clicking the Save or Export button.</li> <li>Resume your session by launching Recce with the specific state file.     <pre><code>recce server recce_issue_1.json\n</code></pre></li> </ol> <p></p>"},{"location":"8-technical-concepts/state-file/#scenario-pr-review","title":"Scenario: PR Review","text":"<p>During the PR review process, the state file serves as a communication medium between the submitter and the reviewer.</p> <ol> <li>Start the Recce server without a state file.     <pre><code>recce server\n</code></pre></li> <li>Add checks to the checklist.</li> <li>Save the state by clicking the Save or Export button.</li> <li>Share the state file with the reviewer or attach it as a comment in the pull request.</li> <li> <p>The reviewer reviews the results using the state file</p> <pre><code>recce server --review recce_issue_1.json\n</code></pre> </li> </ol> <p></p>"}]}